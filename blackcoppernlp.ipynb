{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMocSykDbuVIzHt02gGaDbf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MandiraBanerjee2001/Mandira2001/blob/main/blackcoppernlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Sentimental Analysis"
      ],
      "metadata": {
        "id": "rRSA8kPHiNQW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQTOZvQol37X"
      },
      "outputs": [],
      "source": [
        "import re #regular ecpression or regex"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify the file path in Google Drive\n",
        "file_path1 = '/content/drive/MyDrive/Stop Words/StopWords_Auditor.txt'\n",
        "file_path2 = '/content/drive/MyDrive/Stop Words/StopWords_Currencies.txt'\n",
        "file_path3 = '/content/drive/MyDrive/Stop Words/StopWords_DatesandNumbers.txt'\n",
        "file_path4 = '/content/drive/MyDrive/Stop Words/StopWords_Generic.txt'\n",
        "file_path5 = '/content/drive/MyDrive/Stop Words/StopWords_GenericLong.txt'\n",
        "file_path6 = '/content/drive/MyDrive/Stop Words/StopWords_Geographic.txt'\n",
        "file_path7 = '/content/drive/MyDrive/Stop Words/StopWords_Names.txt'\n",
        "\n",
        "encodings_to_try = ['utf-8', 'latin-1', 'ISO-8859-1']\n",
        "\n",
        "df1 = None\n",
        "df2 = None\n",
        "df3 = None\n",
        "df4 = None\n",
        "df5 = None\n",
        "df6 = None\n",
        "df7 = None\n",
        "\n",
        "for encoding in encodings_to_try:\n",
        "    try:\n",
        "        # Load the text data into a Pandas DataFrame\n",
        "        df1 = pd.read_csv(file_path1, delimiter='|', header=None, names=['Name'], encoding=encoding)\n",
        "        df2 = pd.read_csv(file_path2, delimiter='|', header=None, names=['Name', 'Countries'], encoding=encoding)\n",
        "        df3 = pd.read_csv(file_path3, delimiter='|', header=None, names=['Denominations', 'Time related','Calendar',' Numbers','Roman numerals'], encoding=encoding)\n",
        "        df4 = pd.read_csv(file_path4, delimiter='|', header=None, names=['Generic'], encoding=encoding)\n",
        "        df5 = pd.read_csv(file_path5, delimiter='|', header=None, names=['GenericLocal'], encoding=encoding)\n",
        "        df6 = pd.read_csv(file_path6, delimiter='|', header=None, names=['Geographic', 'Cities','Countries'], encoding=encoding)\n",
        "        df7 = pd.read_csv(file_path7, delimiter='|', header=None, names=['SurName', 'FemaleName',\"CommonSurName\"], encoding=encoding)\n",
        "        break  # Stop trying encodings if successful\n",
        "    except UnicodeDecodeError:\n",
        "\n",
        "        continue  # Try the next encoding\n",
        "\n",
        "# Remove empty lines from the DataFrame\n",
        "df1 = df1.dropna()\n",
        "df2 = df2.dropna()\n",
        "df3 = df3.dropna()\n",
        "df4 = df4.dropna()\n",
        "df5 = df5.dropna()\n",
        "df6 = df6.dropna()\n",
        "df7 = df7.dropna()\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(df1.head())\n",
        "print(df2.head())\n",
        "print(df3.head())\n",
        "print(df4.head())\n",
        "print(df5.head())\n",
        "print(df6.head())\n",
        "print(df7.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3_ExaV5lo5k",
        "outputId": "a9b35392-87c3-4cde-b7c7-02c10d108f2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "       Name\n",
            "0     ERNST\n",
            "1     YOUNG\n",
            "2  DELOITTE\n",
            "3    TOUCHE\n",
            "4      KPMG\n",
            "        Name      Countries\n",
            "0  AFGHANI     Afghanistan \n",
            "1    ARIARY     Madagascar \n",
            "2      BAHT       Thailand \n",
            "3    BALBOA         Panama \n",
            "4      BIRR       Ethiopia \n",
            "Empty DataFrame\n",
            "Columns: [Denominations, Time related, Calendar,  Numbers, Roman numerals]\n",
            "Index: []\n",
            "  Generic\n",
            "0   ABOUT\n",
            "1   ABOVE\n",
            "2   AFTER\n",
            "3   AGAIN\n",
            "4     ALL\n",
            "  GenericLocal\n",
            "0            a\n",
            "1          a's\n",
            "2         able\n",
            "3        about\n",
            "4        above\n",
            "Empty DataFrame\n",
            "Columns: [Geographic, Cities, Countries]\n",
            "Index: []\n",
            "Empty DataFrame\n",
            "Columns: [SurName, FemaleName, CommonSurName]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "JeV8Bp-U-hvA",
        "outputId": "828e28f3-8fe7-461d-e06f-c07c12cc617e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Name\n",
              "0                   ERNST\n",
              "1                   YOUNG\n",
              "2                DELOITTE\n",
              "3                  TOUCHE\n",
              "4                    KPMG\n",
              "5  PRICEWATERHOUSECOOPERS\n",
              "6         PRICEWATERHOUSE\n",
              "7                 COOPERS"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37b045e7-e1cf-458f-aae4-3ce990b23c9b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ERNST</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>YOUNG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DELOITTE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TOUCHE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>KPMG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>PRICEWATERHOUSECOOPERS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>PRICEWATERHOUSE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>COOPERS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37b045e7-e1cf-458f-aae4-3ce990b23c9b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-37b045e7-e1cf-458f-aae4-3ce990b23c9b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-37b045e7-e1cf-458f-aae4-3ce990b23c9b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4e4d663e-56d6-450d-9f78-3d811dfe534d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4e4d663e-56d6-450d-9f78-3d811dfe534d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4e4d663e-56d6-450d-9f78-3d811dfe534d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ede7607c-2c60-49d3-8a41-f82a0b58619a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df1')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ede7607c-2c60-49d3-8a41-f82a0b58619a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df1');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "NoQHIiES-lRn",
        "outputId": "9c9a064b-b670-45d0-bc13-276d44cb1f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Name       Countries\n",
              "0   AFGHANI      Afghanistan \n",
              "1     ARIARY      Madagascar \n",
              "2       BAHT        Thailand \n",
              "3     BALBOA          Panama \n",
              "4       BIRR        Ethiopia \n",
              "..        ...             ...\n",
              "80   TUGRIK         Mongolia \n",
              "81      VATU         Vanuatu \n",
              "82      WON     Korea, South \n",
              "83       YEN           Japan \n",
              "84     ZLOTY          Poland \n",
              "\n",
              "[85 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-811a1afa-82bd-4948-9ff5-e34fc5286839\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Countries</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AFGHANI</td>\n",
              "      <td>Afghanistan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ARIARY</td>\n",
              "      <td>Madagascar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BAHT</td>\n",
              "      <td>Thailand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BALBOA</td>\n",
              "      <td>Panama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BIRR</td>\n",
              "      <td>Ethiopia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>TUGRIK</td>\n",
              "      <td>Mongolia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>VATU</td>\n",
              "      <td>Vanuatu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>WON</td>\n",
              "      <td>Korea, South</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>YEN</td>\n",
              "      <td>Japan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>ZLOTY</td>\n",
              "      <td>Poland</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>85 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-811a1afa-82bd-4948-9ff5-e34fc5286839')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-811a1afa-82bd-4948-9ff5-e34fc5286839 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-811a1afa-82bd-4948-9ff5-e34fc5286839');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bd9faa2e-8b73-414d-898a-614714761139\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bd9faa2e-8b73-414d-898a-614714761139')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bd9faa2e-8b73-414d-898a-614714761139 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9a00f13b-c289-4a18-9d5d-89dfac49728c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9a00f13b-c289-4a18-9d5d-89dfac49728c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "AFePjoKm-lV6",
        "outputId": "247bde41-8ef8-4cba-a59b-6a606e0ea6bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Denominations, Time related, Calendar,  Numbers, Roman numerals]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-140bf3d1-8a78-497b-9394-9adeb928b467\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Denominations</th>\n",
              "      <th>Time related</th>\n",
              "      <th>Calendar</th>\n",
              "      <th>Numbers</th>\n",
              "      <th>Roman numerals</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-140bf3d1-8a78-497b-9394-9adeb928b467')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-140bf3d1-8a78-497b-9394-9adeb928b467 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-140bf3d1-8a78-497b-9394-9adeb928b467');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_318e4d0a-045b-46f6-ae08-798e9f02ec96\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df3')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_318e4d0a-045b-46f6-ae08-798e9f02ec96 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df3');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "wddThR4g-lZz",
        "outputId": "8596c99d-e445-4b16-c0f8-2ae2e3d20330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Generic\n",
              "0         ABOUT\n",
              "1         ABOVE\n",
              "2         AFTER\n",
              "3         AGAIN\n",
              "4           ALL\n",
              "..          ...\n",
              "116         YOU\n",
              "117        YOUR\n",
              "118       YOURS\n",
              "119    YOURSELF\n",
              "120  YOURSELVES\n",
              "\n",
              "[121 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a85a52dd-b862-4b50-bd2e-7e0ffc542c9f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Generic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ABOUT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ABOVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AFTER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AGAIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ALL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>YOU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>YOUR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>YOURS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>YOURSELF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>YOURSELVES</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>121 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a85a52dd-b862-4b50-bd2e-7e0ffc542c9f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a85a52dd-b862-4b50-bd2e-7e0ffc542c9f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a85a52dd-b862-4b50-bd2e-7e0ffc542c9f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0da987b1-7a90-4ea3-ac1e-f4107d51b2c2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0da987b1-7a90-4ea3-ac1e-f4107d51b2c2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0da987b1-7a90-4ea3-ac1e-f4107d51b2c2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d56aa9ff-cd05-48e8-b0d3-7904ac579c6a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df4')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d56aa9ff-cd05-48e8-b0d3-7904ac579c6a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df4');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "qXMvkeuc-lnz",
        "outputId": "aa2ae880-1dd5-48af-c05c-37cb81800224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    GenericLocal\n",
              "0              a\n",
              "1            a's\n",
              "2           able\n",
              "3          about\n",
              "4          above\n",
              "..           ...\n",
              "566        yours\n",
              "567     yourself\n",
              "568   yourselves\n",
              "569            z\n",
              "570         zero\n",
              "\n",
              "[571 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5170f6ff-f95b-4a7f-98f9-d4680f12d137\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GenericLocal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a's</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>able</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>about</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>above</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>yours</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>yourself</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>yourselves</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>569</th>\n",
              "      <td>z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570</th>\n",
              "      <td>zero</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>571 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5170f6ff-f95b-4a7f-98f9-d4680f12d137')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5170f6ff-f95b-4a7f-98f9-d4680f12d137 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5170f6ff-f95b-4a7f-98f9-d4680f12d137');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-03e9cf3e-273c-47db-b5fc-0a0703a0c18c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-03e9cf3e-273c-47db-b5fc-0a0703a0c18c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-03e9cf3e-273c-47db-b5fc-0a0703a0c18c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9e4417b9-86aa-46ea-ba11-db16b8e1e3ac\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df5')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9e4417b9-86aa-46ea-ba11-db16b8e1e3ac button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df5');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "hFak-IyG--yQ",
        "outputId": "6c359243-ebb7-4dff-b5a4-6486c8ab9fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Geographic, Cities, Countries]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58e86e87-f18a-4317-976c-f69d1e3243c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Geographic</th>\n",
              "      <th>Cities</th>\n",
              "      <th>Countries</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58e86e87-f18a-4317-976c-f69d1e3243c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-58e86e87-f18a-4317-976c-f69d1e3243c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-58e86e87-f18a-4317-976c-f69d1e3243c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_e76b4f50-6929-4795-b793-f24ea914a064\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df6')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e76b4f50-6929-4795-b793-f24ea914a064 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df6');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "LOR0QXKW_BTw",
        "outputId": "2600c379-3554-49b2-cab1-25595659bb9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [SurName, FemaleName, CommonSurName]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-940628cf-17c8-4a37-969d-5532e7e70587\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SurName</th>\n",
              "      <th>FemaleName</th>\n",
              "      <th>CommonSurName</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-940628cf-17c8-4a37-969d-5532e7e70587')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-940628cf-17c8-4a37-969d-5532e7e70587 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-940628cf-17c8-4a37-969d-5532e7e70587');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_205d70ff-e3f8-4525-b73b-053ea0570b42\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df7')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_205d70ff-e3f8-4525-b73b-053ea0570b42 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df7');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.1 Cleaning using Stop words list"
      ],
      "metadata": {
        "id": "GGW_2hCfivP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data cleaning and preprocessing\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9_Jdrp4lt5C",
        "outputId": "51cc1d2a-713f-4218-9b64-8b383fe6b1b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download NLTK stop words (do this only once)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Sample dataset\n",
        "dataset2 = [\"/content/drive/MyDrive/Stop Words/StopWords_Currencies.txt\"]\n",
        "dataset1 = ['/content/drive/MyDrive/Stop Words/StopWords_Auditor.txt']\n",
        "dataset3 = ['/content/drive/MyDrive/Stop Words/StopWords_DatesandNumbers.txt']\n",
        "dataset4 = ['/content/drive/MyDrive/Stop Words/StopWords_Generic.txt']\n",
        "dataset5 = ['/content/drive/MyDrive/Stop Words/StopWords_GenericLong.txt']\n",
        "dataset6 = ['/content/drive/MyDrive/Stop Words/StopWords_Geographic.txt']\n",
        "dataset7 = ['/content/drive/MyDrive/Stop Words/StopWords_Names.txt']\n",
        "\n",
        "# Function to remove stop words\n",
        "def remove_stop_words(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = word_tokenize(text)\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "# Apply the function to each item in the dataset\n",
        "cleaned_dataset1 = [remove_stop_words(text) for text in dataset1]\n",
        "cleaned_dataset2 = [remove_stop_words(text) for text in dataset2]\n",
        "cleaned_dataset3 = [remove_stop_words(text) for text in dataset3]\n",
        "cleaned_dataset4 = [remove_stop_words(text) for text in dataset4]\n",
        "cleaned_dataset5 = [remove_stop_words(text) for text in dataset5]\n",
        "cleaned_dataset6 = [remove_stop_words(text) for text in dataset6]\n",
        "cleaned_dataset7 = [remove_stop_words(text) for text in dataset7]\n",
        "\n",
        "\n",
        "# Display the cleaned dataset\n",
        "print(cleaned_dataset1)\n",
        "print(cleaned_dataset2)\n",
        "print(cleaned_dataset3)\n",
        "print(cleaned_dataset4)\n",
        "print(cleaned_dataset5)\n",
        "print(cleaned_dataset6)\n",
        "print(cleaned_dataset7)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX8w8iH7sDEm",
        "outputId": "9fc855ca-a050-4ed3-d876-b5c4f30b6a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Stop Words/StopWords_Auditor.txt']\n",
            "['/content/drive/MyDrive/Stop Words/StopWords_Currencies.txt']\n",
            "['/content/drive/MyDrive/Stop Words/StopWords_DatesandNumbers.txt']\n",
            "['/content/drive/MyDrive/Stop Words/StopWords_Generic.txt']\n",
            "['/content/drive/MyDrive/Stop Words/StopWords_GenericLong.txt']\n",
            "['/content/drive/MyDrive/Stop Words/StopWords_Geographic.txt']\n",
            "['/content/drive/MyDrive/Stop Words/StopWords_Names.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample dataset\n",
        "dataset = [\"/content/drive/MyDrive/Stop Words/StopWords_Currencies.txt\"]\n",
        "\n",
        "# Custom stop words list\n",
        "custom_stop_words = [\"this\", \"is\", \"a\", \"from\"]\n",
        "\n",
        "# Function to remove stop words using a custom list\n",
        "def remove_stop_words_custom(text, stop_words):\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "# Apply the function to each item in the dataset\n",
        "cleaned_dataset_custom = [remove_stop_words_custom(text, custom_stop_words) for text in dataset]\n",
        "\n",
        "# Display the cleaned dataset\n",
        "print(cleaned_dataset_custom)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhOsNqtQsRfg",
        "outputId": "df6d2b08-d3b9-45bf-88c7-12a5905052b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Stop Words/StopWords_Currencies.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a dictionary of Positive and Negative words"
      ],
      "metadata": {
        "id": "Zn2Cu-sejF_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample datasets\n",
        "dataset1 = [\"/content/drive/MyDrive/master dicctionary/negative-words.txt\"]\n",
        "dataset2 = [\"/content/drive/MyDrive/master dicctionary/positive-words.txt\"]\n",
        "\n",
        "# Sample positive and negative word lists\n",
        "positive_words = []\n",
        "negative_words = []\n",
        "\n",
        "# Function to create a sentiment dictionary\n",
        "def create_sentiment_dictionary(dataset, positive_words, negative_words):\n",
        "    sentiment_dict = {\"positive\": 0, \"negative\": 0}\n",
        "\n",
        "    for text in dataset:\n",
        "        words = text.split()\n",
        "        for word in words:\n",
        "            if word.lower() in positive_words:\n",
        "                sentiment_dict[\"positive\"] += 1\n",
        "            elif word.lower() in negative_words:\n",
        "                sentiment_dict[\"negative\"] += 1\n",
        "\n",
        "    return sentiment_dict\n",
        "\n",
        "# Create sentiment dictionaries for both datasets\n",
        "sentiment_dict_dataset1 = create_sentiment_dictionary(dataset1, positive_words, negative_words)\n",
        "sentiment_dict_dataset2 = create_sentiment_dictionary(dataset2, positive_words, negative_words)\n",
        "\n",
        "# Combine the dictionaries\n",
        "combined_sentiment_dict = {\n",
        "    \"positive\": sentiment_dict_dataset1[\"positive\"] + sentiment_dict_dataset2[\"positive\"],\n",
        "    \"negative\": sentiment_dict_dataset1[\"negative\"] + sentiment_dict_dataset2[\"negative\"]\n",
        "}\n",
        "\n",
        "# Display the combined sentiment dictionary\n",
        "print(\"Combined Sentiment Dictionary:\", combined_sentiment_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7pzvCQuuR-h",
        "outputId": "f596005f-93ba-4e30-ca6b-d6c4c0b271ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Sentiment Dictionary: {'positive': 0, 'negative': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chardet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZX4dKjfzLKP",
        "outputId": "5f65bf4c-332e-4fed-96ef-e6140a69193f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (5.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chardet\n",
        "\n",
        "# Function to detect file encoding\n",
        "def detect_encoding(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        result = chardet.detect(f.read())\n",
        "    return result['encoding']\n",
        "\n",
        "# Load positive and negative word lists with detected encoding\n",
        "positive_words_file_path = '/content/drive/MyDrive/master dicctionary/negative-words.txt'\n",
        "negative_words_file_path = '/content/drive/MyDrive/master dicctionary/positive-words.txt'\n",
        "\n",
        "# Detect encoding for positive words file\n",
        "positive_encoding = detect_encoding(positive_words_file_path)\n",
        "\n",
        "# Load positive words with detected encoding\n",
        "with open(positive_words_file_path, 'r', encoding=positive_encoding) as positive_words_file:\n",
        "    positive_words = set(positive_words_file.read().splitlines())\n",
        "\n",
        "# Detect encoding for negative words file\n",
        "negative_encoding = detect_encoding(negative_words_file_path)\n",
        "\n",
        "# Load negative words with detected encoding\n",
        "with open(negative_words_file_path, 'r', encoding=negative_encoding) as negative_words_file:\n",
        "    negative_words = set(negative_words_file.read().splitlines())\n"
      ],
      "metadata": {
        "id": "8Ycd1EZ_zY8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FUhT6tbzjeP",
        "outputId": "5d081a65-e950-4015-8519-82dff9895d93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'austere',\n",
              " 'despoil',\n",
              " 'filthy',\n",
              " 'gape',\n",
              " 'gall',\n",
              " 'tenderness',\n",
              " 'hawkish',\n",
              " 'sketchy',\n",
              " 'bragger',\n",
              " 'spookier',\n",
              " 'liars',\n",
              " 'distorted',\n",
              " 'dwindling',\n",
              " 'foolishness',\n",
              " 'drunken',\n",
              " 'deluge',\n",
              " 'bloated',\n",
              " 'discrimination',\n",
              " 'frighten',\n",
              " 'worried',\n",
              " 'temper',\n",
              " 'intrusive',\n",
              " 'mournful',\n",
              " 'radicals',\n",
              " 'hustler',\n",
              " 'torture',\n",
              " 'misfortune',\n",
              " 'disagreement',\n",
              " 'dogmatic',\n",
              " 'accost',\n",
              " 'bloodshed',\n",
              " 'clogs',\n",
              " 'devilishly',\n",
              " 'hard-line',\n",
              " 'mire',\n",
              " 'limited',\n",
              " 'niggle',\n",
              " 'molestation',\n",
              " 'baffling',\n",
              " 'brood',\n",
              " 'infidels',\n",
              " 'strangely',\n",
              " 'incessantly',\n",
              " 'exorbitantly',\n",
              " 'mist',\n",
              " 'prisoner',\n",
              " 'twist',\n",
              " 'accursed',\n",
              " 'villian',\n",
              " 'dissidents',\n",
              " 'shipwreck',\n",
              " 'irrationality',\n",
              " 'corrupting',\n",
              " 'invalidity',\n",
              " 'crumple',\n",
              " 'simplistic',\n",
              " 'startle',\n",
              " 'despondence',\n",
              " 'picketing',\n",
              " 'anarchist',\n",
              " 'fanatical',\n",
              " 'fraud',\n",
              " 'flickers',\n",
              " 'bulkier',\n",
              " 'poverty',\n",
              " 'idiocies',\n",
              " 'cautionary',\n",
              " 'superstitious',\n",
              " 'illogically',\n",
              " 'inaudible',\n",
              " 'tangled',\n",
              " 'morbid',\n",
              " 'inaction',\n",
              " 'convoluted',\n",
              " 'misbecome',\n",
              " 'mistrustful',\n",
              " 'pitiless',\n",
              " 'ruins',\n",
              " 'irrecoverable',\n",
              " '2-faces',\n",
              " 'devilry',\n",
              " 'inefficiently',\n",
              " 'lugubrious',\n",
              " 'insignificance',\n",
              " 'joke',\n",
              " 'madly',\n",
              " 'licentiousness',\n",
              " 'mindlessly',\n",
              " 'confusions',\n",
              " 'disturb',\n",
              " 'debt',\n",
              " 'relapse',\n",
              " 'reprehensive',\n",
              " 'evasion',\n",
              " 'rollercoaster',\n",
              " 'defiant',\n",
              " 'coercion',\n",
              " 'concens',\n",
              " 'grouse',\n",
              " 'miscreants',\n",
              " 'ingrate',\n",
              " 'misery',\n",
              " 'defiantly',\n",
              " 'raped',\n",
              " 'vexingly',\n",
              " 'unwillingly',\n",
              " 'die',\n",
              " 'polarisation',\n",
              " 'irritable',\n",
              " 'disregardful',\n",
              " 'degenerately',\n",
              " 'fearsome',\n",
              " 'impious',\n",
              " 'lacking',\n",
              " 'disgust',\n",
              " 'plagiarize',\n",
              " 'rampage',\n",
              " 'banalize',\n",
              " 'impropriety',\n",
              " 'relentlessly',\n",
              " 'regression',\n",
              " 'mislead',\n",
              " 'sadly',\n",
              " 'tiringly',\n",
              " 'steals',\n",
              " 'vengeance',\n",
              " 'cheater',\n",
              " 'butcher',\n",
              " 'ranted',\n",
              " 'gawky',\n",
              " 'pratfall',\n",
              " 'irresolvable',\n",
              " 'lying',\n",
              " 'bullies',\n",
              " 'fluster',\n",
              " 'problem',\n",
              " 'gaff',\n",
              " 'unwell',\n",
              " 'falsely',\n",
              " 'implacable',\n",
              " 'polution',\n",
              " 'shrilly',\n",
              " 'defunct',\n",
              " 'incorrect',\n",
              " 'grieving',\n",
              " 'castigate',\n",
              " 'spurn',\n",
              " 'stalemate',\n",
              " 'frazzled',\n",
              " 'indignity',\n",
              " 'prohibitively',\n",
              " 'troubling',\n",
              " 'whore',\n",
              " 'hassles',\n",
              " 'incredulous',\n",
              " 'infested',\n",
              " 'boring',\n",
              " 'shambles',\n",
              " 'stereotypical',\n",
              " 'evade',\n",
              " 'strut',\n",
              " 'undefined',\n",
              " 'unwarranted',\n",
              " 'worrier',\n",
              " 'rumor',\n",
              " 'slump',\n",
              " 'freezing',\n",
              " 'uproariously',\n",
              " 'womanizer',\n",
              " 'trick',\n",
              " 'broken-hearted',\n",
              " 'debauchery',\n",
              " 'burn',\n",
              " 'back-logged',\n",
              " 'sneak',\n",
              " 'rip-off',\n",
              " 'unable',\n",
              " 'indecisive',\n",
              " 'hopelessness',\n",
              " 'prison',\n",
              " 'manipulate',\n",
              " 'undocumented',\n",
              " 'uproarious',\n",
              " 'barbaric',\n",
              " 'maladjustment',\n",
              " 'confused',\n",
              " 'monotony',\n",
              " 'distaste',\n",
              " 'declaim',\n",
              " 'exploitation',\n",
              " 'unmoved',\n",
              " 'ironic',\n",
              " 'ineloquent',\n",
              " 'admonishingly',\n",
              " 'belittle',\n",
              " 'disloyalty',\n",
              " 'repugnant',\n",
              " 'sensationalize',\n",
              " 'jealously',\n",
              " 'listless',\n",
              " 'dastardly',\n",
              " 'objection',\n",
              " 'wobble',\n",
              " 'credulous',\n",
              " 'paradoxical',\n",
              " 'sinister',\n",
              " 'apocalyptic',\n",
              " 'blaspheme',\n",
              " 'barbarian',\n",
              " 'creep',\n",
              " 'hurtful',\n",
              " 'starvation',\n",
              " 'drippy',\n",
              " 'horrendously',\n",
              " 'mock',\n",
              " 'scarred',\n",
              " 'criminal',\n",
              " 'cliche',\n",
              " 'deceptive',\n",
              " 'deprive',\n",
              " 'doddering',\n",
              " 'indecision',\n",
              " 'irreversible',\n",
              " 'indiscernible',\n",
              " 'infringe',\n",
              " 'inveigle',\n",
              " 'pickets',\n",
              " 'expel',\n",
              " 'kill',\n",
              " 'last-ditch',\n",
              " 'subjection',\n",
              " 'stumps',\n",
              " 'downfallen',\n",
              " 'commiserate',\n",
              " 'flat-out',\n",
              " 'smokescreen',\n",
              " 'issues',\n",
              " 'clamor',\n",
              " 'hatefully',\n",
              " 'inescapably',\n",
              " 'little-known',\n",
              " 'abscond',\n",
              " 'grapple',\n",
              " 'contention',\n",
              " 'belligerent',\n",
              " 'hurts',\n",
              " 'sufferer',\n",
              " 'clogged',\n",
              " 'scratchy',\n",
              " 'impunity',\n",
              " 'bid-rigging',\n",
              " 'clique',\n",
              " 'mordantly',\n",
              " 'offend',\n",
              " 'unfriendly',\n",
              " 'boastful',\n",
              " 'fracture',\n",
              " 'hoodium',\n",
              " 'fallacies',\n",
              " 'impolitic',\n",
              " 'cheesy',\n",
              " 'fat-cat',\n",
              " 'sore',\n",
              " 'rigidity',\n",
              " 'deplorable',\n",
              " 'stinging',\n",
              " 'drones',\n",
              " 'exagerated',\n",
              " 'choppy',\n",
              " 'unuseably',\n",
              " 'hypocrite',\n",
              " 'lech',\n",
              " 'temptation',\n",
              " 'stunt',\n",
              " 'unauthentic',\n",
              " 'unprepared',\n",
              " 'dismissive',\n",
              " 'wanton',\n",
              " 'fatally',\n",
              " 'despotism',\n",
              " 'discriminate',\n",
              " 'lure',\n",
              " 'sued',\n",
              " 'wrongful',\n",
              " 'throbs',\n",
              " 'ire',\n",
              " 'violation',\n",
              " 'unsuspecting',\n",
              " 'downhearted',\n",
              " 'flak',\n",
              " 'tortures',\n",
              " 'woebegone',\n",
              " 'bafflement',\n",
              " 'lewdness',\n",
              " 'motley',\n",
              " 'darken',\n",
              " 'enmity',\n",
              " 'forfeit',\n",
              " 'precariously',\n",
              " 'unorthodox',\n",
              " 'harsh',\n",
              " 'ding',\n",
              " 'wariness',\n",
              " 'entrapment',\n",
              " 'forebodingly',\n",
              " 'suppression',\n",
              " 'stingy',\n",
              " 'disintegrated',\n",
              " 'impudently',\n",
              " 'criticizing',\n",
              " 'killjoy',\n",
              " 'disown',\n",
              " 'overturn',\n",
              " 'erase',\n",
              " 'rejecting',\n",
              " 'dinky',\n",
              " 'interference',\n",
              " 'appall',\n",
              " 'defiance',\n",
              " 'attack',\n",
              " 'jutters',\n",
              " 'mispronounces',\n",
              " 'd*mn',\n",
              " 'animosity',\n",
              " 'censure',\n",
              " 'oppress',\n",
              " 'oppressively',\n",
              " 'perplex',\n",
              " 'scramble',\n",
              " 'grouch',\n",
              " 'frustratingly',\n",
              " 'manipulation',\n",
              " 'capitulate',\n",
              " 'notorious',\n",
              " 'declines',\n",
              " 'wasted',\n",
              " 'imposition',\n",
              " 'excruciating',\n",
              " 'jaded',\n",
              " 'exasperated',\n",
              " 'nauseate',\n",
              " 'hard',\n",
              " 'contemptible',\n",
              " 'incomparably',\n",
              " 'lies',\n",
              " 'taut',\n",
              " 'impedance',\n",
              " 'droop',\n",
              " 'succumb',\n",
              " 'discourteous',\n",
              " 'drop-outs',\n",
              " 'treason',\n",
              " 'cataclysmically',\n",
              " 'rigid',\n",
              " 'cold',\n",
              " 'stealing',\n",
              " 'worn',\n",
              " 'castrated',\n",
              " 'furious',\n",
              " 'rascals',\n",
              " 'drastic',\n",
              " 'ranting',\n",
              " 'aimless',\n",
              " 'awfully',\n",
              " 'cloud',\n",
              " 'disfavor',\n",
              " 'douchebags',\n",
              " 'tank',\n",
              " 'miserably',\n",
              " 'hardened',\n",
              " 'ignoble',\n",
              " 'unuseable',\n",
              " 'ridicules',\n",
              " 'covetous',\n",
              " 'madder',\n",
              " 'overpayed',\n",
              " 'shriek',\n",
              " 'overzealous',\n",
              " 'dunce',\n",
              " 'offensively',\n",
              " 'overpower',\n",
              " 'volatile',\n",
              " 'zap',\n",
              " 'imbalance',\n",
              " 'disses',\n",
              " 'implausible',\n",
              " 'infuriated',\n",
              " 'brutality',\n",
              " 'misunderstandings',\n",
              " 'spoon-feed',\n",
              " 'equivocal',\n",
              " 'murky',\n",
              " 'cry',\n",
              " 'pretentious',\n",
              " 'disdainful',\n",
              " 'rumple',\n",
              " 'messing',\n",
              " 'barbarically',\n",
              " 'disvalue',\n",
              " 'pettifog',\n",
              " 'rigidness',\n",
              " 'stutters',\n",
              " 'suspicion',\n",
              " 'unhappily',\n",
              " 'goon',\n",
              " 'awkward',\n",
              " 'blurry',\n",
              " 'futile',\n",
              " 'dragoon',\n",
              " 'slow',\n",
              " 'debaucher',\n",
              " 'resignation',\n",
              " 'squash',\n",
              " 'intimidate',\n",
              " 'helplessness',\n",
              " 'puppets',\n",
              " 'catastrophies',\n",
              " 'radical',\n",
              " 'opportunistic',\n",
              " 'oddity',\n",
              " 'incorrectly',\n",
              " 'outsider',\n",
              " 'anti-israeli',\n",
              " 'bumpy',\n",
              " 'bleeding',\n",
              " 'ill-designed',\n",
              " 'complicit',\n",
              " 'over-balanced',\n",
              " 'uncomfortable',\n",
              " 'shameful',\n",
              " 'struggling',\n",
              " 'impugn',\n",
              " 'counterproductive',\n",
              " 'bristle',\n",
              " 'futilely',\n",
              " 'weirdly',\n",
              " 'bewilder',\n",
              " 'blameworthy',\n",
              " 'pricey',\n",
              " 'discourage',\n",
              " 'emphatic',\n",
              " 'lag',\n",
              " 'exorbitantance',\n",
              " 'ultimatums',\n",
              " 'irredeemably',\n",
              " 'sh*t',\n",
              " 'dripping',\n",
              " 'heretical',\n",
              " 'ill-natured',\n",
              " 'pedantic',\n",
              " 'lacks',\n",
              " 'provocation',\n",
              " 'dreary',\n",
              " 'skimpy',\n",
              " 'subpoena',\n",
              " 'disrespectfulness',\n",
              " 'boggle',\n",
              " 'unneeded',\n",
              " 'bickering',\n",
              " 'shadowy',\n",
              " 'destructive',\n",
              " 'mar',\n",
              " 'odd',\n",
              " 'aches',\n",
              " 'refusing',\n",
              " 'shame',\n",
              " 'tyrannically',\n",
              " 'blundering',\n",
              " 'famished',\n",
              " 'incompetence',\n",
              " 'disapointing',\n",
              " 'insubordinate',\n",
              " 'malign',\n",
              " 'occlude',\n",
              " 'sporadic',\n",
              " 'gaffe',\n",
              " 'stringently',\n",
              " 'swollen',\n",
              " 'blinding',\n",
              " 'tardy',\n",
              " 'untenable',\n",
              " 'pinch',\n",
              " 'exorbitant',\n",
              " 'scolded',\n",
              " 'unsure',\n",
              " 'surrender',\n",
              " 'assassinate',\n",
              " 'misread',\n",
              " 'ridicule',\n",
              " 'confront',\n",
              " 'frail',\n",
              " 'sloow',\n",
              " 'bemoan',\n",
              " 'forbidden',\n",
              " 'harm',\n",
              " 'travesties',\n",
              " 'improbable',\n",
              " 'attacks',\n",
              " 'calumniation',\n",
              " 'frenzy',\n",
              " 'pernicious',\n",
              " 'puny',\n",
              " 'defile',\n",
              " 'snagged',\n",
              " 'misapprehend',\n",
              " 'punk',\n",
              " 'infest',\n",
              " 'ill-defined',\n",
              " 'belittling',\n",
              " 'cramped',\n",
              " 'flee',\n",
              " 'impulsively',\n",
              " 'quibbles',\n",
              " 'hissed',\n",
              " 'long-winded',\n",
              " 'disturbing',\n",
              " 'reviled',\n",
              " 'sorrow',\n",
              " 'discontinued',\n",
              " 'hardship',\n",
              " 'unfavorable',\n",
              " 'annoyingly',\n",
              " 'incorrigibly',\n",
              " 'sagged',\n",
              " 'unreachable',\n",
              " 'worries',\n",
              " 'uncooperative',\n",
              " 'crooked',\n",
              " 'damnation',\n",
              " 'pitiable',\n",
              " 'enemy',\n",
              " 'plunder',\n",
              " 'harridan',\n",
              " 'smutty',\n",
              " 'bombardment',\n",
              " 'anti-us',\n",
              " 'bruises',\n",
              " 'cannibal',\n",
              " 'disparagingly',\n",
              " 'profanity',\n",
              " 'clamorous',\n",
              " 'servitude',\n",
              " 'inconvenience',\n",
              " 'drastically',\n",
              " 'stumped',\n",
              " 'contemptuously',\n",
              " 'backache',\n",
              " 'insolent',\n",
              " 'unkind',\n",
              " 'high-priced',\n",
              " 'reprove',\n",
              " 'chill',\n",
              " 'resigned',\n",
              " 'uncouth',\n",
              " 'venomous',\n",
              " 'wildly',\n",
              " 'inhumanity',\n",
              " 'deadly',\n",
              " 'self-humiliation',\n",
              " 'dope',\n",
              " 'decrepitude',\n",
              " 'hideously',\n",
              " 'precipitous',\n",
              " 'dumb',\n",
              " 'indecisively',\n",
              " 'indiscriminately',\n",
              " 'ruined',\n",
              " 'lividly',\n",
              " 'oppose',\n",
              " 'horrifys',\n",
              " 'skeptic',\n",
              " 'bashing',\n",
              " 'zaps',\n",
              " 'enjoin',\n",
              " 'bull****',\n",
              " 'liar',\n",
              " 'repudiation',\n",
              " 'revulsive',\n",
              " 'selfinterested',\n",
              " 'dispirited',\n",
              " 'taint',\n",
              " 'fever',\n",
              " 'fatigued',\n",
              " 'boisterous',\n",
              " 'vociferous',\n",
              " 'catastrophes',\n",
              " 'hysterically',\n",
              " 'shroud',\n",
              " 'intrusion',\n",
              " 'abominably',\n",
              " 'bulkiness',\n",
              " 'gripe',\n",
              " 'tyrant',\n",
              " 'flakey',\n",
              " 'grating',\n",
              " 'inconsequent',\n",
              " 'undercut',\n",
              " 'unforeseen',\n",
              " 'accidental',\n",
              " 'apathetically',\n",
              " 'anemic',\n",
              " 'impeach',\n",
              " 'ferociously',\n",
              " 'infamously',\n",
              " 'self-coup',\n",
              " 'snobish',\n",
              " 'absent-minded',\n",
              " 'counter-productive',\n",
              " 'breaks',\n",
              " 'degeneration',\n",
              " 'deteriorating',\n",
              " 'siege',\n",
              " 'complains',\n",
              " 'impetuous',\n",
              " 'audacious',\n",
              " 'disconsolate',\n",
              " 'stuck',\n",
              " 'unqualified',\n",
              " 'despoiler',\n",
              " 'bruise',\n",
              " 'hating',\n",
              " 'reluctantly',\n",
              " 'baseless',\n",
              " 'hestitant',\n",
              " 'spoonfed',\n",
              " 'apologist',\n",
              " 'inhospitality',\n",
              " 'degenerate',\n",
              " 'disinterested',\n",
              " 'barbarously',\n",
              " 'curses',\n",
              " 'incomplete',\n",
              " 'lapses',\n",
              " 'indeterminably',\n",
              " 'biting',\n",
              " 'isolation',\n",
              " 'arduous',\n",
              " 'non-confidence',\n",
              " 'pitifully',\n",
              " 'stymied',\n",
              " 'bereft',\n",
              " 'drawback',\n",
              " 'propaganda',\n",
              " 'discordant',\n",
              " 'unseemly',\n",
              " 'semi-retarded',\n",
              " 'cracked',\n",
              " 'dishearten',\n",
              " 'disaccord',\n",
              " 'critic',\n",
              " 'indelicate',\n",
              " 'shabby',\n",
              " 'reprovingly',\n",
              " 'sarcastic',\n",
              " 'ordeal',\n",
              " 'weird',\n",
              " 'pry',\n",
              " 'merciless',\n",
              " 'grainy',\n",
              " 'resurgent',\n",
              " 'unhappy',\n",
              " 'drag',\n",
              " 'discombobulate',\n",
              " 'brainless',\n",
              " 'uncompromising',\n",
              " 'unexpected',\n",
              " 'weaken',\n",
              " 'overbalanced',\n",
              " 'hallucinate',\n",
              " 'disillusions',\n",
              " 'detestable',\n",
              " 'devilment',\n",
              " 'brutalities',\n",
              " 'sues',\n",
              " 'oblique',\n",
              " 'unwelcome',\n",
              " 'bs',\n",
              " 'grumpier',\n",
              " 'fallaciously',\n",
              " 'immobilized',\n",
              " 'invisible',\n",
              " 'emphatically',\n",
              " 'kills',\n",
              " 'shimmer',\n",
              " 'exploit',\n",
              " 'chide',\n",
              " 'scoldingly',\n",
              " 'villainous',\n",
              " 'contend',\n",
              " 'strenuous',\n",
              " 'nebulous',\n",
              " 'fustigate',\n",
              " 'dogged',\n",
              " 'unrelenting',\n",
              " 'inconsiderately',\n",
              " 'embarrassing',\n",
              " 'sucks',\n",
              " 'inculcate',\n",
              " 'confuse',\n",
              " 'hegemonistic',\n",
              " 'disgusted',\n",
              " 'perilous',\n",
              " 'nervous',\n",
              " 'diatribe',\n",
              " 'conscons',\n",
              " 'insufficient',\n",
              " 'adverse',\n",
              " 'juddering',\n",
              " 'detests',\n",
              " 'flees',\n",
              " 'fuss',\n",
              " 'inattentive',\n",
              " 'disquietude',\n",
              " 'mortified',\n",
              " 'outrages',\n",
              " 'atrocities',\n",
              " 'crush',\n",
              " 'squeal',\n",
              " 'plot',\n",
              " 'disagrees',\n",
              " 'hedonistic',\n",
              " 'dissembler',\n",
              " 'lonesome',\n",
              " 'stale',\n",
              " 'audacity',\n",
              " 'straggler',\n",
              " 'steal',\n",
              " 'difficult',\n",
              " 'misrepresent',\n",
              " 'notoriously',\n",
              " 'aggrivation',\n",
              " 'pauper',\n",
              " 'rattled',\n",
              " 'incompatible',\n",
              " 'rumors',\n",
              " 'ugly',\n",
              " 'bemoaning',\n",
              " 'fat-cats',\n",
              " 'muddy',\n",
              " 'risk',\n",
              " 'denunciation',\n",
              " 'abrupt',\n",
              " 'maddening',\n",
              " 'uneventful',\n",
              " 'sunder',\n",
              " 'hogs',\n",
              " 'harassed',\n",
              " 'dying',\n",
              " 'trouble',\n",
              " 'unreasonable',\n",
              " 'abominate',\n",
              " 'hindrance',\n",
              " 'jeeringly',\n",
              " 'hell',\n",
              " 'premeditated',\n",
              " 'ingratitude',\n",
              " 'audiciously',\n",
              " 'dirtbag',\n",
              " 'inequitably',\n",
              " 'detracting',\n",
              " 'fallacy',\n",
              " 'downer',\n",
              " 'over-awe',\n",
              " 'complain',\n",
              " 'cloudy',\n",
              " 'dreadfulness',\n",
              " 'calumniate',\n",
              " 'fanatically',\n",
              " 'gruff',\n",
              " 'hang',\n",
              " 'frenetic',\n",
              " 'instable',\n",
              " 'deficient',\n",
              " 'invidiously',\n",
              " 'shortcomings',\n",
              " 'impermissible',\n",
              " 'stupidly',\n",
              " 'spoils',\n",
              " 'disapprove',\n",
              " 'disillusioned',\n",
              " 'snagging',\n",
              " 'rivalry',\n",
              " 'alarmingly',\n",
              " 'exile',\n",
              " 'wrip',\n",
              " 'mistified',\n",
              " 'woefully',\n",
              " 'unaccessible',\n",
              " 'massacre',\n",
              " 'imperiously',\n",
              " 'uprising',\n",
              " 'bothersome',\n",
              " 'crass',\n",
              " 'frightful',\n",
              " 'lesser-known',\n",
              " 'expulse',\n",
              " 'matte',\n",
              " 'hardball',\n",
              " 'noises',\n",
              " 'worthlessness',\n",
              " 'conspicuously',\n",
              " 'insulting',\n",
              " 'terror-genic',\n",
              " 'contentious',\n",
              " 'devilish',\n",
              " 'noisy',\n",
              " 'detract',\n",
              " 'resistance',\n",
              " 'fascism',\n",
              " 'trashed',\n",
              " 'harboring',\n",
              " 'crisis',\n",
              " 'sickness',\n",
              " 'pessimistically',\n",
              " 'revoke',\n",
              " 'treachery',\n",
              " 'savages',\n",
              " 'unsteady',\n",
              " 'buzzing',\n",
              " 'forlorn',\n",
              " 'dismalness',\n",
              " 'unknown',\n",
              " 'thoughtlessness',\n",
              " 'irresolute',\n",
              " 'aloof',\n",
              " 'stampede',\n",
              " 'unsound',\n",
              " 'brutally',\n",
              " 'smell',\n",
              " 'acrimoniously',\n",
              " 'arbitrary',\n",
              " 'annoying',\n",
              " 'brash',\n",
              " 'floored',\n",
              " 'horrifying',\n",
              " 'obsessiveness',\n",
              " 'crashes',\n",
              " 'unnerved',\n",
              " 'worse',\n",
              " 'selfishly',\n",
              " 'swipe',\n",
              " 'irritant',\n",
              " 'sneeringly',\n",
              " 'hum',\n",
              " 'cataclysmic',\n",
              " 'appallingly',\n",
              " 'wretchedness',\n",
              " 'mess',\n",
              " 'bravado',\n",
              " 'moribund',\n",
              " 'irksome',\n",
              " 'wripped',\n",
              " 'impiety',\n",
              " 'quack',\n",
              " 'procrastinate',\n",
              " 'insubstantial',\n",
              " 'plight',\n",
              " 'ill-tempered',\n",
              " 'darker',\n",
              " 'ill-treated',\n",
              " 'fundamentalism',\n",
              " 'entanglement',\n",
              " 'protracted',\n",
              " 'careless',\n",
              " 'reject',\n",
              " 'overemphasize',\n",
              " 'kook',\n",
              " 'wreaks',\n",
              " 'enemies',\n",
              " 'shamelessly',\n",
              " 'ghastly',\n",
              " 'beg',\n",
              " 'direly',\n",
              " 'scandalously',\n",
              " 'spiritless',\n",
              " 'strict',\n",
              " 'upsettingly',\n",
              " 'forbid',\n",
              " 'lacked',\n",
              " 'pillory',\n",
              " 'gloom',\n",
              " 'revengeful',\n",
              " 'dragged',\n",
              " 'sagging',\n",
              " 'bewilderingly',\n",
              " 'confound',\n",
              " 'distorts',\n",
              " 'imprudent',\n",
              " 'martyrdom',\n",
              " 'aspersion',\n",
              " 'feverish',\n",
              " 'insult',\n",
              " 'outrageously',\n",
              " 'tetchy',\n",
              " 'wane',\n",
              " 'finagle',\n",
              " 'scream',\n",
              " 'lame-duck',\n",
              " 'peeled',\n",
              " 'perverse',\n",
              " 'smells',\n",
              " 'dimmer',\n",
              " 'blow',\n",
              " 'battering',\n",
              " 'diss',\n",
              " 'incongruous',\n",
              " 'waste',\n",
              " 'obscures',\n",
              " 'fanatic',\n",
              " 'disoriented',\n",
              " 'fathomless',\n",
              " 'inequities',\n",
              " 'muscle-flexing',\n",
              " 'wrestle',\n",
              " 'bruised',\n",
              " 'delirium',\n",
              " 'anti-white',\n",
              " 'inteferes',\n",
              " 'disinclination',\n",
              " 'cumbersome',\n",
              " 'disbelief',\n",
              " 'ignominiously',\n",
              " 'chasten',\n",
              " 'detraction',\n",
              " 'detracts',\n",
              " 'disintegrate',\n",
              " 'racism',\n",
              " 'grisly',\n",
              " 'disparaging',\n",
              " 'malice',\n",
              " 'hideous',\n",
              " 'misreading',\n",
              " 'opinionated',\n",
              " 'superficial',\n",
              " 'testy',\n",
              " 'unfaithfully',\n",
              " 'alarming',\n",
              " 'bastard',\n",
              " 'absurd',\n",
              " 'mendacity',\n",
              " 'dissident',\n",
              " 'downturn',\n",
              " 'dust',\n",
              " 'die-hard',\n",
              " 'maddeningly',\n",
              " 'scandalized',\n",
              " 'snub',\n",
              " 'dissension',\n",
              " 'malady',\n",
              " 'skeptical',\n",
              " 'disappointed',\n",
              " 'gibber',\n",
              " 'catastrophic',\n",
              " 'expropriate',\n",
              " 'polluter',\n",
              " 'criticisms',\n",
              " 'waning',\n",
              " 'instability',\n",
              " 'insufferably',\n",
              " 'revenge',\n",
              " 'destitution',\n",
              " 'beggarly',\n",
              " 'warp',\n",
              " 'fiend',\n",
              " 'loose',\n",
              " 'mysterious',\n",
              " 'obscurity',\n",
              " 'contaminating',\n",
              " 'crowded',\n",
              " 'decrepit',\n",
              " 'encroachment',\n",
              " 'rifts',\n",
              " 'tattered',\n",
              " 'defective',\n",
              " 'depravedly',\n",
              " 'orphan',\n",
              " 'mistake',\n",
              " 'innuendo',\n",
              " 'bereavement',\n",
              " 'low-rated',\n",
              " 'mortify',\n",
              " 'oppressiveness',\n",
              " 'deploring',\n",
              " 'incivility',\n",
              " 'pout',\n",
              " 'aversion',\n",
              " 'helpless',\n",
              " 'foul',\n",
              " 'reprehensibly',\n",
              " 'scandalous',\n",
              " 'shrill',\n",
              " 'intrude',\n",
              " 'unprofitable',\n",
              " 'phobia',\n",
              " 'uncaring',\n",
              " 'adamantly',\n",
              " 'quarrellous',\n",
              " 'melancholy',\n",
              " 'debaser',\n",
              " 'damning',\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "negative_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cjs6QP3Kzqzb",
        "outputId": "2ae90170-7cfe-49aa-bc60-052fd58ee9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'enticed',\n",
              " 'foresight',\n",
              " 'brighten',\n",
              " 'virtue',\n",
              " 'dignified',\n",
              " 'blissfully',\n",
              " 'outsmart',\n",
              " 'exalt',\n",
              " 'sturdier',\n",
              " 'spectacularly',\n",
              " 'hearten',\n",
              " 'rapt',\n",
              " 'upliftment',\n",
              " 'instrumental',\n",
              " 'issue-free',\n",
              " 'admiring',\n",
              " 'revelation',\n",
              " 'leads',\n",
              " 'praise',\n",
              " 'jolly',\n",
              " 'staunch',\n",
              " 'merry',\n",
              " 'calming',\n",
              " 'eyecatch',\n",
              " 'easier',\n",
              " 'enviably',\n",
              " 'prodigiously',\n",
              " 'prudent',\n",
              " 'maturity',\n",
              " 'outstandingly',\n",
              " 'gladden',\n",
              " 'eye-catching',\n",
              " 'preferring',\n",
              " 'joyfully',\n",
              " 'enthusiastically',\n",
              " 'bullish',\n",
              " 'agile',\n",
              " 'exceptionally',\n",
              " 'glorious',\n",
              " 'tempting',\n",
              " 'perfect',\n",
              " 'impartially',\n",
              " 'intuitive',\n",
              " 'gratify',\n",
              " 'advantageous',\n",
              " 'delicate',\n",
              " 'uplifting',\n",
              " 'frugal',\n",
              " 'proficient',\n",
              " 'progress',\n",
              " 'swiftness',\n",
              " 'supporting',\n",
              " 'gush',\n",
              " 'exquisite',\n",
              " 'finer',\n",
              " 'illuminate',\n",
              " 'fame',\n",
              " 'courageousness',\n",
              " 'speedy',\n",
              " 'politeness',\n",
              " 'pampered',\n",
              " 'magnificent',\n",
              " 'amicably',\n",
              " 'outperformed',\n",
              " 'attractive',\n",
              " 'magnificently',\n",
              " 'luckier',\n",
              " 'achievements',\n",
              " 'fidelity',\n",
              " 'smile',\n",
              " 'credence',\n",
              " 'prettily',\n",
              " 'adore',\n",
              " 'sumptuous',\n",
              " 'unreal',\n",
              " 'protection',\n",
              " 'zest',\n",
              " 'capably',\n",
              " 'irreproachable',\n",
              " 'unrivaled',\n",
              " 'upheld',\n",
              " 'ingeniously',\n",
              " 'pleasantly',\n",
              " 'victorious',\n",
              " 'openly',\n",
              " 'excellently',\n",
              " 'fresh',\n",
              " 'patriot',\n",
              " 'awe',\n",
              " 'inspiring',\n",
              " 'commendably',\n",
              " 'succeeds',\n",
              " 'advocate',\n",
              " 'invulnerable',\n",
              " 'luckiness',\n",
              " 'sustainability',\n",
              " 'nicely',\n",
              " 'irreplaceable',\n",
              " 'better-known',\n",
              " 'jollify',\n",
              " 'admiration',\n",
              " 'reaffirm',\n",
              " 'yay',\n",
              " 'fanfare',\n",
              " 'counter-attack',\n",
              " 'simplify',\n",
              " 'gooood',\n",
              " 'nicest',\n",
              " 'razor-sharp',\n",
              " 'variety',\n",
              " 'incredible',\n",
              " 'divine',\n",
              " 'foremost',\n",
              " 'justly',\n",
              " 'thankful',\n",
              " 'prosperity',\n",
              " 'enhancement',\n",
              " 'pleasure',\n",
              " 'recommended',\n",
              " 'tenaciously',\n",
              " 'luster',\n",
              " 'passionately',\n",
              " 'versatile',\n",
              " 'gusto',\n",
              " 'poise',\n",
              " 'eases',\n",
              " 'enchant',\n",
              " 'complements',\n",
              " 'inspirational',\n",
              " 'adventuresome',\n",
              " 'affluence',\n",
              " 'conciliate',\n",
              " 'enough',\n",
              " 'masterful',\n",
              " 'pleasurably',\n",
              " 'fancier',\n",
              " 'swanky',\n",
              " 'bonny',\n",
              " 'outperforming',\n",
              " 'enterprising',\n",
              " 'liberation',\n",
              " 'loves',\n",
              " 'kid-friendly',\n",
              " 'educated',\n",
              " 'wowing',\n",
              " 'indebted',\n",
              " 'recommend',\n",
              " 'stellar',\n",
              " 'excite',\n",
              " 'stabilize',\n",
              " 'ultra-crisp',\n",
              " 'beckons',\n",
              " 'agreeable',\n",
              " 'contentment',\n",
              " 'success',\n",
              " 'applaud',\n",
              " 'consistent',\n",
              " 'danke',\n",
              " 'upscale',\n",
              " 'securely',\n",
              " 'clarity',\n",
              " 'lawfully',\n",
              " 'awed',\n",
              " 'compliant',\n",
              " 'instantly',\n",
              " 'creative',\n",
              " 'innovative',\n",
              " 'enjoyed',\n",
              " 'excellency',\n",
              " 'prefers',\n",
              " 'promising',\n",
              " 'reassure',\n",
              " 'well-backlit',\n",
              " 'tenacity',\n",
              " 'harmonious',\n",
              " 'vibrant',\n",
              " 'gifted',\n",
              " 'congratulate',\n",
              " 'guiltless',\n",
              " 'glowingly',\n",
              " 'rejuvenated',\n",
              " 'ftw',\n",
              " 'glamorous',\n",
              " 'sincerely',\n",
              " 'fastest',\n",
              " 'geeky',\n",
              " 'smiles',\n",
              " 'humorous',\n",
              " 'amazing',\n",
              " 'witty',\n",
              " 'exhilarate',\n",
              " 'simplest',\n",
              " 'sufficient',\n",
              " 'chivalrous',\n",
              " 'angel',\n",
              " 'renowned',\n",
              " 'hands-down',\n",
              " 'replaceable',\n",
              " 'inviolable',\n",
              " 'smooth',\n",
              " 'novelty',\n",
              " 'bountiful',\n",
              " 'beckoning',\n",
              " 'consummate',\n",
              " 'heal',\n",
              " 'easy',\n",
              " 'purify',\n",
              " 'maneuverable',\n",
              " 'peaceful',\n",
              " 'achievible',\n",
              " 'eagerness',\n",
              " 'gainful',\n",
              " 'carefree',\n",
              " 'hero',\n",
              " 'illumine',\n",
              " 'continuity',\n",
              " 'remedy',\n",
              " 'like',\n",
              " 'beutifully',\n",
              " 'lyrical',\n",
              " 'dominate',\n",
              " 'flattering',\n",
              " 'idyllic',\n",
              " 'sweetly',\n",
              " 'amazes',\n",
              " 'promises',\n",
              " 'richer',\n",
              " 'silent',\n",
              " 'enhances',\n",
              " 'excellent',\n",
              " 'tolerable',\n",
              " 'empowerment',\n",
              " 'stylishly',\n",
              " 'support',\n",
              " 'topnotch',\n",
              " 'momentous',\n",
              " 'first-in-class',\n",
              " 'romanticize',\n",
              " 'cashback',\n",
              " 'fearlessly',\n",
              " 'goodly',\n",
              " 'rockstars',\n",
              " 'salute',\n",
              " 'noiseless',\n",
              " 'effectiveness',\n",
              " 'flutter',\n",
              " 'strong',\n",
              " 'dote',\n",
              " 'lovably',\n",
              " 'toll-free',\n",
              " 'accomplished',\n",
              " 'enthrall',\n",
              " 'neatly',\n",
              " 'wellbeing',\n",
              " 'enlightenment',\n",
              " 'capability',\n",
              " 'delightfulness',\n",
              " 'pepped',\n",
              " 'beautifully',\n",
              " 'supporter',\n",
              " 'appropriate',\n",
              " 'amazed',\n",
              " 'ecstatically',\n",
              " 'ready',\n",
              " 'stately',\n",
              " 'navigable',\n",
              " 'gorgeously',\n",
              " 'standout',\n",
              " 'courageously',\n",
              " 'mesmerized',\n",
              " 'sophisticated',\n",
              " 'flourishing',\n",
              " 'exceeding',\n",
              " 'excel',\n",
              " 'receptive',\n",
              " 'cleared',\n",
              " 'joyful',\n",
              " 'painlessly',\n",
              " 'valor',\n",
              " 'fulfillment',\n",
              " 'paradise',\n",
              " 'brighter',\n",
              " 'rightly',\n",
              " 'winning',\n",
              " 'invigorate',\n",
              " 'jubiliant',\n",
              " 'pretty',\n",
              " 'improving',\n",
              " 'relief',\n",
              " 'embolden',\n",
              " 'glad',\n",
              " 'brand-new',\n",
              " 'nourishment',\n",
              " 'perfectly',\n",
              " 'stellarly',\n",
              " 'tantalizing',\n",
              " 'amusingly',\n",
              " 'unfettered',\n",
              " 'bliss',\n",
              " 'god-send',\n",
              " 'marvelled',\n",
              " 'conciliatory',\n",
              " 'buoyant',\n",
              " 'revive',\n",
              " 'priceless',\n",
              " 'masterfully',\n",
              " 'intelligible',\n",
              " 'profuse',\n",
              " 'quiet',\n",
              " 'striving',\n",
              " 'congratulation',\n",
              " 'kudos',\n",
              " 'fortuitously',\n",
              " 'trumpet',\n",
              " 'assure',\n",
              " 'worth-while',\n",
              " 'record-setting',\n",
              " 'aspiration',\n",
              " 'adjustable',\n",
              " 'enrichment',\n",
              " 'convincingly',\n",
              " 'steadfastly',\n",
              " 'majesty',\n",
              " 'assurance',\n",
              " 'enrapt',\n",
              " 'winner',\n",
              " 'steadiness',\n",
              " 'clears',\n",
              " 'entertains',\n",
              " 'greatness',\n",
              " 'sensation',\n",
              " 'harmoniously',\n",
              " 'hardy',\n",
              " 'err-free',\n",
              " 'nourish',\n",
              " 'sane',\n",
              " 'wonderfully',\n",
              " 'hopeful',\n",
              " 'enrich',\n",
              " 'lover',\n",
              " 'exhilaratingly',\n",
              " 'led',\n",
              " 'smartest',\n",
              " 'eminent',\n",
              " 'respectfully',\n",
              " 'excellence',\n",
              " 'fortitude',\n",
              " 'stability',\n",
              " 'raptureously',\n",
              " 'gracious',\n",
              " 'healthy',\n",
              " 'permissible',\n",
              " 'privilege',\n",
              " 'treasure',\n",
              " 'morality',\n",
              " 'quicker',\n",
              " 'thrillingly',\n",
              " 'striking',\n",
              " 'undaunted',\n",
              " 'perseverance',\n",
              " 'exaltingly',\n",
              " 'cashbacks',\n",
              " 'superb',\n",
              " 'beloved',\n",
              " 'angelic',\n",
              " 'positive',\n",
              " 'prominent',\n",
              " 'eyecatching',\n",
              " 'warmly',\n",
              " 'better',\n",
              " 'entrancing',\n",
              " 'graciously',\n",
              " 'handsomely',\n",
              " 'frolic',\n",
              " 'shimmering',\n",
              " 'warmhearted',\n",
              " 'booming',\n",
              " 'effusive',\n",
              " 'sweetheart',\n",
              " 'diligence',\n",
              " 'rejuvenating',\n",
              " 'sparkle',\n",
              " 'marveled',\n",
              " 'respectable',\n",
              " 'supurb',\n",
              " 'fabulously',\n",
              " 'outstrip',\n",
              " 'finely',\n",
              " 'tougher',\n",
              " 'jaw-droping',\n",
              " 'rightful',\n",
              " 'outshone',\n",
              " 'interests',\n",
              " 'unequivocally',\n",
              " 'intelligence',\n",
              " 'rewarding',\n",
              " 'defender',\n",
              " 'fine-looking',\n",
              " 'positively',\n",
              " 'joy',\n",
              " 'engrossing',\n",
              " 'grateful',\n",
              " 'excels',\n",
              " 'suavely',\n",
              " 'unassailable',\n",
              " 'invigorating',\n",
              " 'speedily',\n",
              " 'enthral',\n",
              " 'upbeat',\n",
              " 'won',\n",
              " 'ecstasies',\n",
              " 'survivor',\n",
              " 'inspire',\n",
              " 'precious',\n",
              " 'delicious',\n",
              " 'smoothes',\n",
              " 'chaste',\n",
              " 'dynamic',\n",
              " 'earnest',\n",
              " 'benefits',\n",
              " 'ameliorate',\n",
              " 'prodigy',\n",
              " 'enthusiast',\n",
              " 'valuable',\n",
              " 'darling',\n",
              " 'spellbound',\n",
              " 'retractable',\n",
              " 'congratulatory',\n",
              " 'first-rate',\n",
              " 'merriment',\n",
              " 'flawlessly',\n",
              " 'profoundly',\n",
              " 'leverage',\n",
              " 'phenomenal',\n",
              " 'achievable',\n",
              " 'roomy',\n",
              " 'eminence',\n",
              " 'superior',\n",
              " 'blockbuster',\n",
              " 'usable',\n",
              " 'ingenuous',\n",
              " 'dauntless',\n",
              " 'adaptable',\n",
              " 'fresher',\n",
              " 'appreciable',\n",
              " 'humane',\n",
              " 'satisfied',\n",
              " 'impresses',\n",
              " 'visionary',\n",
              " 'enchanting',\n",
              " 'windfall',\n",
              " 'zippy',\n",
              " 'heartwarming',\n",
              " 'redeeming',\n",
              " 'charisma',\n",
              " 'defeated',\n",
              " 'peps',\n",
              " 'remission',\n",
              " 'adulation',\n",
              " 'glowing',\n",
              " 'enchantingly',\n",
              " 'alluringly',\n",
              " 'fancinating',\n",
              " 'successes',\n",
              " 'substantive',\n",
              " 'lifesaver',\n",
              " 'desiring',\n",
              " 'orderly',\n",
              " 'comprehensive',\n",
              " 'trusting',\n",
              " 'rejuvenate',\n",
              " 'fluent',\n",
              " 'sprightly',\n",
              " 'ecstasy',\n",
              " 'easy-to-use',\n",
              " 'providence',\n",
              " 'wisely',\n",
              " 'polite',\n",
              " 'daringly',\n",
              " 'undamaged',\n",
              " 'contrasty',\n",
              " 'extoll',\n",
              " 'triumphal',\n",
              " 'intelligent',\n",
              " 'popular',\n",
              " 'win',\n",
              " 'idolize',\n",
              " 'agreeableness',\n",
              " 'happier',\n",
              " 'keenly',\n",
              " 'examplar',\n",
              " 'lead',\n",
              " 'honored',\n",
              " 'beautiful',\n",
              " 'enhance',\n",
              " 'realizable',\n",
              " 'defeating',\n",
              " 'proactive',\n",
              " 'affectionate',\n",
              " 'honoring',\n",
              " 'swift',\n",
              " 'capable',\n",
              " 'spellbindingly',\n",
              " 'thinner',\n",
              " 'economical',\n",
              " 'sensibly',\n",
              " 'breathtakingly',\n",
              " 'respite',\n",
              " 'spirited',\n",
              " 'calm',\n",
              " 'honorable',\n",
              " 'low-risk',\n",
              " 'stainless',\n",
              " 'illustrious',\n",
              " 'compassionate',\n",
              " 'adorable',\n",
              " 'hottest',\n",
              " 'propitious',\n",
              " 'effusiveness',\n",
              " 'ingenuously',\n",
              " 'saintliness',\n",
              " 'reforms',\n",
              " 'reputable',\n",
              " 'respect',\n",
              " 'happily',\n",
              " 'exuberantly',\n",
              " 'balanced',\n",
              " 'reverently',\n",
              " 'edify',\n",
              " 'nourishing',\n",
              " 'charitable',\n",
              " 'reverent',\n",
              " 'immense',\n",
              " 'efficacious',\n",
              " 'reclaim',\n",
              " 'instructive',\n",
              " 'painless',\n",
              " 'achievement',\n",
              " 'commitment',\n",
              " 'feasible',\n",
              " 'pleasant',\n",
              " 'diligent',\n",
              " 'reaffirmation',\n",
              " 'courageous',\n",
              " 'willing',\n",
              " 'patriotic',\n",
              " 'propitiously',\n",
              " 'sensitive',\n",
              " 'virtuously',\n",
              " 'fervor',\n",
              " 'bonus',\n",
              " 'captivating',\n",
              " 'heartily',\n",
              " 'sweeten',\n",
              " 'dexterous',\n",
              " 'cheery',\n",
              " 'succeed',\n",
              " 'powerfully',\n",
              " 'saint',\n",
              " 'smart',\n",
              " 'miraculously',\n",
              " 'fearless',\n",
              " 'traction',\n",
              " 'promised',\n",
              " 'gains',\n",
              " 'long-lasting',\n",
              " 'unabashedly',\n",
              " 'safely',\n",
              " 'pain-free',\n",
              " 'awesomeness',\n",
              " 'affable',\n",
              " 'positives',\n",
              " 'genuine',\n",
              " 'clearly',\n",
              " 'hale',\n",
              " 'rockstar',\n",
              " 'fertile',\n",
              " 'prospros',\n",
              " 'smiling',\n",
              " 'generously',\n",
              " 'unbeatable',\n",
              " 'jaw-dropping',\n",
              " 'articulate',\n",
              " 'lovable',\n",
              " 'danken',\n",
              " 'hail',\n",
              " 'low-priced',\n",
              " 'prompt',\n",
              " 'adulate',\n",
              " 'cherish',\n",
              " 'miraculous',\n",
              " 'celebrated',\n",
              " 'purposeful',\n",
              " 'accomplishment',\n",
              " 'accolades',\n",
              " 'dummy-proof',\n",
              " 'masterpieces',\n",
              " 'prudence',\n",
              " 'resourceful',\n",
              " 'obtainable',\n",
              " 'works',\n",
              " 'marvellous',\n",
              " 'deft',\n",
              " 'thank',\n",
              " 'breeze',\n",
              " 'gallantly',\n",
              " 'compatible',\n",
              " 'preferable',\n",
              " 'exquisitely',\n",
              " 'obsessions',\n",
              " 'advocates',\n",
              " 'well-made',\n",
              " 'halcyon',\n",
              " 'trendy',\n",
              " 'individualized',\n",
              " 'spellbind',\n",
              " 'masters',\n",
              " 'well-connected',\n",
              " 'crisp',\n",
              " 'fair',\n",
              " 'sharp',\n",
              " 'revolutionize',\n",
              " 'eulogize',\n",
              " 'indulgent',\n",
              " 'refunded',\n",
              " 'terrifically',\n",
              " 'lucky',\n",
              " 'indulgence',\n",
              " 'exemplary',\n",
              " 'invaluablely',\n",
              " 'winners',\n",
              " 'amusing',\n",
              " 'easing',\n",
              " 'fairly',\n",
              " 'comforting',\n",
              " 'soothingly',\n",
              " 'believeable',\n",
              " 'cost-saving',\n",
              " 'pride',\n",
              " 'scenic',\n",
              " 'irresistibly',\n",
              " 'beneficiary',\n",
              " 'champion',\n",
              " 'decisive',\n",
              " 'mighty',\n",
              " 'admirably',\n",
              " 'aver',\n",
              " 'grace',\n",
              " 'benevolence',\n",
              " 'decent',\n",
              " 'revolutionized',\n",
              " 'best-selling',\n",
              " 'pleasurable',\n",
              " 'affordably',\n",
              " 'thrilling',\n",
              " 'restructure',\n",
              " 'succes',\n",
              " 'reconciliation',\n",
              " 'exhilarating',\n",
              " 'neatest',\n",
              " 'winnable',\n",
              " 'encouragingly',\n",
              " 'lower-priced',\n",
              " 'awsome',\n",
              " 'joyous',\n",
              " 'astutely',\n",
              " 'pamperedness',\n",
              " 'satisfying',\n",
              " 'modern',\n",
              " 'bolster',\n",
              " 'optimistic',\n",
              " 'spectacular',\n",
              " 'endorsed',\n",
              " 'upgraded',\n",
              " 'stimulate',\n",
              " 'fortunately',\n",
              " 'endorses',\n",
              " 'meticulously',\n",
              " 'notably',\n",
              " 'successfully',\n",
              " 'great',\n",
              " 'subsidizing',\n",
              " 'erudite',\n",
              " 'unforgettable',\n",
              " 'interesting',\n",
              " 'spontaneous',\n",
              " 'smoothly',\n",
              " 'gladly',\n",
              " 'enlighten',\n",
              " 'renewed',\n",
              " 'avid',\n",
              " 'low-cost',\n",
              " 'gaining',\n",
              " 'portable',\n",
              " 'ambitiously',\n",
              " 'reverence',\n",
              " 'comely',\n",
              " 'amenable',\n",
              " 'sublime',\n",
              " 'charismatic',\n",
              " 'merit',\n",
              " 'rejoicing',\n",
              " 'supported',\n",
              " 'boom',\n",
              " 'greatest',\n",
              " 'proper',\n",
              " 'excelent',\n",
              " 'superiority',\n",
              " 'evenly',\n",
              " 'law-abiding',\n",
              " 'affably',\n",
              " 'affordable',\n",
              " 'beauteous',\n",
              " 'faith',\n",
              " 'gratification',\n",
              " 'zenith',\n",
              " 'talent',\n",
              " 'astonishingly',\n",
              " 'fascinate',\n",
              " 'attentive',\n",
              " 'tantalize',\n",
              " 'blameless',\n",
              " 'simpler',\n",
              " 'stable',\n",
              " 'celebratory',\n",
              " 'cooperatively',\n",
              " 'liked',\n",
              " 'pampers',\n",
              " 'steady',\n",
              " 'merciful',\n",
              " 'vivid',\n",
              " 'poeticize',\n",
              " 'benevolent',\n",
              " 'compact',\n",
              " 'unbiased',\n",
              " 'invaluable',\n",
              " 'loved',\n",
              " 'respectful',\n",
              " 'motivated',\n",
              " 'free',\n",
              " 'effusively',\n",
              " 'aspire',\n",
              " 'romantically',\n",
              " 'expansive',\n",
              " 'precise',\n",
              " 'well-run',\n",
              " 'plentiful',\n",
              " 'brisk',\n",
              " 'blissful',\n",
              " 'entertain',\n",
              " 'gaiety',\n",
              " 'well-educated',\n",
              " 'suitable',\n",
              " 'prize',\n",
              " 'appreciatively',\n",
              " 'contribution',\n",
              " 'hardier',\n",
              " 'intimacy',\n",
              " 'fortuitous',\n",
              " 'affluent',\n",
              " 'abundance',\n",
              " 'afford',\n",
              " 'fascinating',\n",
              " 'lush',\n",
              " 'rectify',\n",
              " 'secure',\n",
              " 'cohere',\n",
              " 'excelled',\n",
              " 'elan',\n",
              " 'nifty',\n",
              " 'flashy',\n",
              " 'supremely',\n",
              " 'peace',\n",
              " 'talents',\n",
              " 'freedoms',\n",
              " 'satisfies',\n",
              " 'advantage',\n",
              " 'piety',\n",
              " 'energize',\n",
              " 'heartening',\n",
              " 'intriguing',\n",
              " 'affinity',\n",
              " 'gracefully',\n",
              " 'auspicious',\n",
              " 'well-positioned',\n",
              " 'ovation',\n",
              " 'precisely',\n",
              " 'successful',\n",
              " 'courteous',\n",
              " 'amaze',\n",
              " 'advocated',\n",
              " 'admire',\n",
              " 'fondly',\n",
              " 'unwavering',\n",
              " 'award',\n",
              " 'everlasting',\n",
              " 'fascinatingly',\n",
              " 'genius',\n",
              " 'beneficent',\n",
              " 'ebulliently',\n",
              " 'upgradable',\n",
              " 'mesmerizing',\n",
              " 'luxury',\n",
              " 'properly',\n",
              " 'sagely',\n",
              " 'gleeful',\n",
              " 'preferes',\n",
              " 'improvements',\n",
              " 'earnestness',\n",
              " 'gentlest',\n",
              " 'steadiest',\n",
              " 'unbound',\n",
              " 'convience',\n",
              " 'loveliness',\n",
              " 'staunchness',\n",
              " 'entranced',\n",
              " 'infallibly',\n",
              " 'exuberance',\n",
              " 'deservedly',\n",
              " 'idealize',\n",
              " 'boost',\n",
              " 'dumbfounding',\n",
              " 'uplift',\n",
              " 'ingenuity',\n",
              " 'breakthrough',\n",
              " 'peacefully',\n",
              " 'overjoyed',\n",
              " 'confidence',\n",
              " 'sagacity',\n",
              " 'soundness',\n",
              " 'compliment',\n",
              " 'fecilitous',\n",
              " 'guidance',\n",
              " 'freed',\n",
              " 'feasibly',\n",
              " 'delighted',\n",
              " 'envious',\n",
              " 'evaluative',\n",
              " 'polished',\n",
              " 'reforming',\n",
              " 'well-behaved',\n",
              " 'slick',\n",
              " 'palatial',\n",
              " 'amiabily',\n",
              " 'freedom',\n",
              " 'outstanding',\n",
              " 'innocuous',\n",
              " 'self-satisfaction',\n",
              " 'harmony',\n",
              " 'prominence',\n",
              " 'complemented',\n",
              " 'protective',\n",
              " 'godlike',\n",
              " 'praising',\n",
              " 'trusty',\n",
              " 'charmingly',\n",
              " 'stimulative',\n",
              " 'risk-free',\n",
              " 'elevate',\n",
              " 'worthy',\n",
              " 'beautify',\n",
              " 'meritorious',\n",
              " 'clever',\n",
              " 'succeeded',\n",
              " 'affection',\n",
              " 'proving',\n",
              " 'electrify',\n",
              " 'heros',\n",
              " 'smarter',\n",
              " 'trump',\n",
              " 'rewardingly',\n",
              " 'effectual',\n",
              " 'premier',\n",
              " 'examplary',\n",
              " 'awards',\n",
              " 'well-established',\n",
              " 'aspirations',\n",
              " 'punctual',\n",
              " 'brainiest',\n",
              " 'amiability',\n",
              " 'truthfulness',\n",
              " 'readily',\n",
              " 'amply',\n",
              " 'beneficial',\n",
              " 'profusion',\n",
              " 'acclaimed',\n",
              " 'fashionably',\n",
              " 'undisputed',\n",
              " 'marvels',\n",
              " 'advantageously',\n",
              " 'mightily',\n",
              " 'exceedingly',\n",
              " 'exuberant',\n",
              " 'awarded',\n",
              " 'ambitious',\n",
              " 'compactly',\n",
              " 'well-intentioned',\n",
              " 'appealing',\n",
              " 'flexible',\n",
              " 'world-famous',\n",
              " 'handsome',\n",
              " 'wonderful',\n",
              " 'helpful',\n",
              " 'impeccably',\n",
              " 'convient',\n",
              " 'intrigue',\n",
              " 'engaging',\n",
              " 'brainy',\n",
              " 'mind-blowing',\n",
              " 'magnanimous',\n",
              " 'rich',\n",
              " 'brightest',\n",
              " 'favorite',\n",
              " 'brilliance',\n",
              " 'persevere',\n",
              " 'holy',\n",
              " 'grandeur',\n",
              " 'preferably',\n",
              " 'celebrate',\n",
              " 'excites',\n",
              " 'brilliantly',\n",
              " 'entertaining',\n",
              " 'comfortably',\n",
              " 'promoter',\n",
              " 'exemplar',\n",
              " 'fond',\n",
              " 'triumph',\n",
              " 'hospitable',\n",
              " 'integrated',\n",
              " 'futurestic',\n",
              " 'freshest',\n",
              " 'delightfully',\n",
              " 'adequate',\n",
              " 'soft',\n",
              " 'nurturing',\n",
              " 'picturesque',\n",
              " 'peppy',\n",
              " 'proven',\n",
              " 'inviolate',\n",
              " 'time-honored',\n",
              " 'enrapture',\n",
              " 'awesomely',\n",
              " 'dazzling',\n",
              " 'handily',\n",
              " 'rectification',\n",
              " 'youthful',\n",
              " 'homage',\n",
              " 'feature-rich',\n",
              " 'helped',\n",
              " 'cornerstone',\n",
              " 'exhilaration',\n",
              " 'refreshed',\n",
              " 'wisdom',\n",
              " 'fun',\n",
              " 'nice',\n",
              " 'tender',\n",
              " 'graceful',\n",
              " 'accomplish',\n",
              " 'trusted',\n",
              " 'commend',\n",
              " 'affability',\n",
              " 'versatility',\n",
              " 'lucrative',\n",
              " 'thriving',\n",
              " 'woo',\n",
              " 'swankier',\n",
              " 'healthful',\n",
              " 'thoughtfulness',\n",
              " 'light-hearted',\n",
              " 'sensible',\n",
              " 'prudently',\n",
              " 'goood',\n",
              " 'elegant',\n",
              " 'agilely',\n",
              " 'restful',\n",
              " 'reconcile',\n",
              " 'conscientious',\n",
              " 'righteousness',\n",
              " 'jubilation',\n",
              " 'whoa',\n",
              " 'cajole',\n",
              " 'righteous',\n",
              " 'astounding',\n",
              " 'enthusiasm',\n",
              " 'restructured',\n",
              " 'top',\n",
              " 'lean',\n",
              " 'levity',\n",
              " 'eased',\n",
              " 'heroically',\n",
              " 'pre-eminent',\n",
              " 'fine',\n",
              " 'thumbs-up',\n",
              " 'satisfy',\n",
              " 'blithe',\n",
              " 'astonishing',\n",
              " 'fondness',\n",
              " 'affirm',\n",
              " 'insightfully',\n",
              " 'refine',\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.3 Extracting Derived variables"
      ],
      "metadata": {
        "id": "EyeJ9EexjXY3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Variables"
      ],
      "metadata": {
        "id": "NlehKBiG2kDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Positive Score"
      ],
      "metadata": {
        "id": "eanpAwGljjeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import os\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "def calculate_positive_score(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            text = file.read()\n",
        "    except UnicodeDecodeError:\n",
        "        print(f\"UnicodeDecodeError: Attempting to open {file_path} with 'latin-1' encoding.\")\n",
        "        with open(file_path, 'r', encoding='latin-1') as file:\n",
        "            text = file.read()\n",
        "\n",
        "    # Create a SentimentIntensityAnalyzer object\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "    # Get the sentiment scores for the text\n",
        "    sentiment_scores = sia.polarity_scores(text)\n",
        "\n",
        "    # The 'compound' score is often used as an overall sentiment score\n",
        "    positive_score = sentiment_scores['pos']\n",
        "\n",
        "    return positive_score\n",
        "\n",
        "file_path1 = \"/content/drive/MyDrive/master dicctionary/negative-words.txt\"\n",
        "file_path2 = \"/content/drive/MyDrive/master dicctionary/positive-words.txt\"\n",
        "\n",
        "\n",
        "# Calculate positive score for each file\n",
        "positive_score1 = calculate_positive_score(file_path1)\n",
        "positive_score2 = calculate_positive_score(file_path2)\n",
        "\n",
        "print(f\"Positive score for file 1: {positive_score1:.4f}\")\n",
        "print(f\"Positive score for file 2: {positive_score2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eczg9u1QfXio",
        "outputId": "67b9a4b6-5924-4d05-98a5-58791f2f1aa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UnicodeDecodeError: Attempting to open /content/drive/MyDrive/master dicctionary/negative-words.txt with 'latin-1' encoding.\n",
            "Positive score for file 1: 0.0070\n",
            "Positive score for file 2: 0.6340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Negative Score"
      ],
      "metadata": {
        "id": "mQqjYGSAjqBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import os\n",
        "\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "def calculate_negative_score(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            text = file.read()\n",
        "    except UnicodeDecodeError:\n",
        "        print(f\"UnicodeDecodeError: Attempting to open {file_path} with 'latin-1' encoding.\")\n",
        "        with open(file_path, 'r', encoding='latin-1') as file:\n",
        "            text = file.read()\n",
        "\n",
        "    # Create a SentimentIntensityAnalyzer object\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "    # Get the sentiment scores for the text\n",
        "    sentiment_scores = sia.polarity_scores(text)\n",
        "\n",
        "    # The 'compound' score is often used as an overall sentiment score\n",
        "    negative_score = sentiment_scores['neg']\n",
        "\n",
        "    return negative_score\n",
        "\n",
        "\n",
        "file_path1 = \"/content/drive/MyDrive/master dicctionary/negative-words.txt\"\n",
        "file_path2 = \"/content/drive/MyDrive/master dicctionary/positive-words.txt\"\n",
        "\n",
        "\n",
        "\n",
        "# Calculate negative score for each file\n",
        "negative_score1 = calculate_negative_score(file_path1)\n",
        "negative_score2 = calculate_negative_score(file_path2)\n",
        "\n",
        "print(f\"Negative score for file 1: {negative_score1:.4f}\")\n",
        "print(f\"Negative score for file 2: {negative_score2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa2yc_UjgTPo",
        "outputId": "90565d3a-50d6-4f68-bde3-238f4fdf31d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UnicodeDecodeError: Attempting to open /content/drive/MyDrive/master dicctionary/negative-words.txt with 'latin-1' encoding.\n",
            "Negative score for file 1: 0.5370\n",
            "Negative score for file 2: 0.0110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Polarity Score"
      ],
      "metadata": {
        "id": "9RFBOFDDjuKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import os\n",
        "\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "def calculate_polarity_score(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            text = file.read()\n",
        "    except UnicodeDecodeError:\n",
        "        print(f\"UnicodeDecodeError: Attempting to open {file_path} with 'latin-1' encoding.\")\n",
        "        with open(file_path, 'r', encoding='latin-1') as file:\n",
        "            text = file.read()\n",
        "\n",
        "    # Create a SentimentIntensityAnalyzer object\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "    # Get the sentiment scores for the text\n",
        "    sentiment_scores = sia.polarity_scores(text)\n",
        "\n",
        "    # The 'compound' score is often used as an overall sentiment score\n",
        "    polarity_score = sentiment_scores['compound']\n",
        "\n",
        "    return polarity_score\n",
        "\n",
        "file_path1 = \"/content/drive/MyDrive/master dicctionary/negative-words.txt\"\n",
        "file_path2 = \"/content/drive/MyDrive/master dicctionary/positive-words.txt\"\n",
        "\n",
        "\n",
        "# Calculate polarity score for each file\n",
        "polarity_score1 = calculate_polarity_score(file_path1)\n",
        "polarity_score2 = calculate_polarity_score(file_path2)\n",
        "\n",
        "print(f\"Polarity score for file 1: {polarity_score1:.4f}\")\n",
        "print(f\"Polarity score for file 2: {polarity_score2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "by6Wnbm6gsMC",
        "outputId": "5ca3e94a-9d76-41eb-fedd-de7b0d5e9ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UnicodeDecodeError: Attempting to open /content/drive/MyDrive/master dicctionary/negative-words.txt with 'latin-1' encoding.\n",
            "Polarity score for file 1: -1.0000\n",
            "Polarity score for file 2: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Subjectivity Score"
      ],
      "metadata": {
        "id": "xPxa0FZujz1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "import os\n",
        "\n",
        "def calculate_subjectivity_score(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            text = file.read()\n",
        "    except UnicodeDecodeError:\n",
        "        print(f\"UnicodeDecodeError: Attempting to open {file_path} with 'latin-1' encoding.\")\n",
        "        with open(file_path, 'r', encoding='latin-1') as file:\n",
        "            text = file.read()\n",
        "\n",
        "    # Create a TextBlob object\n",
        "    blob = TextBlob(text)\n",
        "\n",
        "    # Get the subjectivity score\n",
        "    subjectivity_score = blob.sentiment.subjectivity\n",
        "\n",
        "    return subjectivity_score\n",
        "\n",
        "\n",
        "file_path1 = \"/content/drive/MyDrive/master dicctionary/negative-words.txt\"\n",
        "file_path2 = \"/content/drive/MyDrive/master dicctionary/positive-words.txt\"\n",
        "\n",
        "\n",
        "\n",
        "# Calculate subjectivity score for each file\n",
        "subjectivity_score1 = calculate_subjectivity_score(file_path1)\n",
        "subjectivity_score2 = calculate_subjectivity_score(file_path2)\n",
        "\n",
        "print(f\"Subjectivity score for file 1: {subjectivity_score1:.4f}\")\n",
        "print(f\"Subjectivity score for file 2: {subjectivity_score2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMzzEwXzhTFt",
        "outputId": "4c8a7805-b9fc-487e-d454-1da1a622fdbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UnicodeDecodeError: Attempting to open /content/drive/MyDrive/master dicctionary/negative-words.txt with 'latin-1' encoding.\n",
            "Subjectivity score for file 1: 0.7366\n",
            "Subjectivity score for file 2: 0.7407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Analysis of Readability"
      ],
      "metadata": {
        "id": "tJWnH1qxj8b-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.Average Sentence Length"
      ],
      "metadata": {
        "id": "3Fdm2anEkFvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')  # Download the Punkt tokenizer model (do this only once)\n",
        "\n",
        "def average_sentence_length(file_path):\n",
        "    with open(file_path, 'r', encoding='latin-1') as file:\n",
        "        text = file.read()\n",
        "\n",
        "    # Tokenize the text into sentences\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "\n",
        "    # Calculate the average sentence length\n",
        "    total_words = sum(len(nltk.word_tokenize(sentence)) for sentence in sentences)\n",
        "    total_sentences = len(sentences)\n",
        "\n",
        "    if total_sentences > 0:\n",
        "        avg_sentence_length = total_words / total_sentences\n",
        "        return avg_sentence_length\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Specify the paths to your text files\n",
        "file_paths1 = ['/content/drive/MyDrive/Stop Words/StopWords_Auditor.txt']\n",
        "file_paths2 = ['/content/drive/MyDrive/Stop Words/StopWords_Currencies.txt']\n",
        "file_paths3 = ['/content/drive/MyDrive/Stop Words/StopWords_DatesandNumbers.txt']\n",
        "file_paths4 = ['/content/drive/MyDrive/Stop Words/StopWords_Generic.txt']\n",
        "file_paths5 = ['/content/drive/MyDrive/Stop Words/StopWords_GenericLong.txt']\n",
        "file_paths6 = ['/content/drive/MyDrive/Stop Words/StopWords_Geographic.txt']\n",
        "file_paths7 = ['/content/drive/MyDrive/Stop Words/StopWords_Names.txt']\n",
        "\n",
        "\n",
        "# Calculate average sentence length for each text file\n",
        "for file_path in file_paths1:\n",
        "    avg_length1 = average_sentence_length(file_path1)\n",
        "    print(f\"Average sentence length for {file_path1}: {avg_length1:.2f} words\")\n",
        "\n",
        "for file_path in file_paths2:\n",
        "    avg_length2 = average_sentence_length(file_path2)\n",
        "    print(f\"Average sentence length for {file_path2}: {avg_length2:.2f} words\")\n",
        "\n",
        "for file_path in file_paths3:\n",
        "    avg_length3 = average_sentence_length(file_path3)\n",
        "    print(f\"Average sentence length for {file_path3}: {avg_length3:.2f} words\")\n",
        "\n",
        "for file_path in file_paths4:\n",
        "    avg_length4 = average_sentence_length(file_path4)\n",
        "    print(f\"Average sentence length for {file_path4}: {avg_length4:.2f} words\")\n",
        "\n",
        "for file_path in file_paths5:\n",
        "    avg_length5 = average_sentence_length(file_path5)\n",
        "    print(f\"Average sentence length for {file_path5}: {avg_length5:.2f} words\")\n",
        "\n",
        "for file_path in file_paths6:\n",
        "    avg_length6 = average_sentence_length(file_path6)\n",
        "    print(f\"Average sentence length for {file_path6}: {avg_length6:.2f} words\")\n",
        "\n",
        "for file_path in file_paths7:\n",
        "    avg_length7 = average_sentence_length(file_path7)\n",
        "    print(f\"Average sentence length for {file_path7}: {avg_length7:.2f} words\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqIKRge6ICfF",
        "outputId": "08a13685-ec72-4985-d657-472988c8893e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average sentence length for /content/drive/MyDrive/Stop Words/StopWords_Auditor.txt: 8.00 words\n",
            "Average sentence length for /content/drive/MyDrive/Stop Words/StopWords_Currencies.txt: 142.00 words\n",
            "Average sentence length for /content/drive/MyDrive/Stop Words/StopWords_DatesandNumbers.txt: 121.00 words\n",
            "Average sentence length for /content/drive/MyDrive/Stop Words/StopWords_Generic.txt: 121.00 words\n",
            "Average sentence length for /content/drive/MyDrive/Stop Words/StopWords_GenericLong.txt: 572.00 words\n",
            "Average sentence length for /content/drive/MyDrive/Stop Words/StopWords_Geographic.txt: 207.00 words\n",
            "Average sentence length for /content/drive/MyDrive/Stop Words/StopWords_Names.txt: 6519.00 words\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.Percentage of Complex Words"
      ],
      "metadata": {
        "id": "-8ZI3U4il4oB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import words as nltk_words  # Rename to avoid conflict\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('words')\n",
        "\n",
        "# Function to calculate the percentage of complex words in a text\n",
        "def percentage_of_complex_words(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            text = file.read()\n",
        "    except UnicodeDecodeError:\n",
        "        print(f\"UnicodeDecodeError: Attempting to open {file_path} with 'latin-1' encoding.\")\n",
        "        with open(file_path, 'r', encoding='latin-1') as file:\n",
        "            text = file.read()\n",
        "\n",
        "    # Tokenize the text\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word.lower() for word in words if word.isalpha() and word.lower() not in stop_words]\n",
        "\n",
        "    # Get a set of English words\n",
        "    english_words = set(nltk_words.words())\n",
        "\n",
        "    # Count the number of complex words\n",
        "    complex_words = [word for word in words if word.lower() in english_words]\n",
        "\n",
        "    # Calculate the percentage of complex words\n",
        "    percentage_complex = (len(complex_words) / len(words)) * 100 if len(words) > 0 else 0\n",
        "\n",
        "    return percentage_complex\n",
        "\n",
        "\n",
        "file_paths = ['/content/drive/MyDrive/Stop Words/StopWords_Auditor.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Currencies.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_DatesandNumbers.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Generic.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_GenericLong.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Geographic.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Names.txt']\n",
        "# Calculate and print the percentage of complex words for each file\n",
        "for file_path in file_paths:\n",
        "    percentage_complex = percentage_of_complex_words(file_path)\n",
        "    print(f\"Percentage of complex words in {file_path}: {percentage_complex:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygUBb3NflHBg",
        "outputId": "3d471ee9-cd66-4dd6-8d85-06cd15f31697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of complex words in /content/drive/MyDrive/Stop Words/StopWords_Auditor.txt: 12.50%\n",
            "UnicodeDecodeError: Attempting to open /content/drive/MyDrive/Stop Words/StopWords_Currencies.txt with 'latin-1' encoding.\n",
            "Percentage of complex words in /content/drive/MyDrive/Stop Words/StopWords_Currencies.txt: 40.84%\n",
            "Percentage of complex words in /content/drive/MyDrive/Stop Words/StopWords_DatesandNumbers.txt: 59.13%\n",
            "Percentage of complex words in /content/drive/MyDrive/Stop Words/StopWords_Generic.txt: 100.00%\n",
            "Percentage of complex words in /content/drive/MyDrive/Stop Words/StopWords_GenericLong.txt: 85.20%\n",
            "Percentage of complex words in /content/drive/MyDrive/Stop Words/StopWords_Geographic.txt: 28.08%\n",
            "Percentage of complex words in /content/drive/MyDrive/Stop Words/StopWords_Names.txt: 18.41%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.Fog Index"
      ],
      "metadata": {
        "id": "4dC0DLWpmt2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import cmudict\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('cmudict')\n",
        "\n",
        "def get_syllable_count(word):\n",
        "    d = cmudict.dict()\n",
        "\n",
        "    # Check if the word is present in the dictionary\n",
        "    if word.lower() in d:\n",
        "        return [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]][0]\n",
        "    else:\n",
        "        # Handle the case where the word is not found in the dictionary\n",
        "        # You might choose to assume one syllable or skip the word\n",
        "        return 1  # Assuming one syllable for unknown words\n",
        "def calculate_fog_index(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    words = word_tokenize(text)\n",
        "    total_words = len(words)\n",
        "    total_sentences = len(sentences)\n",
        "\n",
        "    complex_words = [word for word in words if get_syllable_count(word) >= 3]\n",
        "    total_complex_words = len(complex_words)\n",
        "\n",
        "    average_sentence_length = total_words / total_sentences\n",
        "    percentage_complex_words = (total_complex_words / total_words) * 100\n",
        "\n",
        "    fog_index = 0.4 * (average_sentence_length + percentage_complex_words)\n",
        "    return fog_index\n",
        "\n",
        "def read_text_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        content = file.read()\n",
        "    return content\n",
        "\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Stop Words/StopWords_Auditor.txt'\n",
        "text_content = read_text_file(file_path)\n",
        "\n",
        "fog_index = calculate_fog_index(text_content)\n",
        "print(f\"The Gunning Fog Index is: {fog_index:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdg8fsjDlyhx",
        "outputId": "0f387d63-528b-4334-ade4-86f2bfba0507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Package cmudict is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Gunning Fog Index is: 3.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import cmudict\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('cmudict')\n",
        "\n",
        "def get_syllable_count(word):\n",
        "    d = cmudict.dict()\n",
        "\n",
        "    # Check if the word is present in the dictionary\n",
        "    if word.lower() in d:\n",
        "        return [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]][0]\n",
        "    else:\n",
        "        # Handle the case where the word is not found in the dictionary\n",
        "        # You might choose to assume one syllable or skip the word\n",
        "        return 1  # Assuming one syllable for unknown words\n",
        "def calculate_fog_index(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    words = word_tokenize(text)\n",
        "    total_words = len(words)\n",
        "    total_sentences = len(sentences)\n",
        "\n",
        "    complex_words = [word for word in words if get_syllable_count(word) >= 3]\n",
        "    total_complex_words = len(complex_words)\n",
        "\n",
        "    average_sentence_length = total_words / total_sentences\n",
        "    percentage_complex_words = (total_complex_words / total_words) * 100\n",
        "\n",
        "    fog_index = 0.4 * (average_sentence_length + percentage_complex_words)\n",
        "    return fog_index\n",
        "\n",
        "\n",
        "\n",
        "def read_text_file(file_path, encodings=('utf-8', 'latin-1')):\n",
        "  for encoding in encodings:\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding=encoding, errors='replace') as file:\n",
        "                content = file.read()\n",
        "            return content\n",
        "        except UnicodeDecodeError:\n",
        "            print(f\"UnicodeDecodeError: Failed to decode using encoding {encoding}. Trying the next one.\")\n",
        "            continue\n",
        "\n",
        "    # If all encodings fail, raise an exception\n",
        "        raise UnicodeDecodeError(\"Unable to decode the file using any of the specified encodings.\")\n",
        "\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Stop Words/StopWords_Currencies.txt'\n",
        "text_content = read_text_file(file_path)\n",
        "\n",
        "fog_index = calculate_fog_index(text_content)\n",
        "print(f\"The Gunning Fog Index is: {fog_index:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSc-k036mrY-",
        "outputId": "eb35781c-cc92-4e4c-e312-0e0a7f800300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Package cmudict is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Gunning Fog Index is: 66.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import cmudict\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('cmudict')\n",
        "\n",
        "def get_syllable_count(word):\n",
        "    d = cmudict.dict()\n",
        "\n",
        "    # Check if the word is present in the dictionary\n",
        "    if word.lower() in d:\n",
        "        return [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]][0]\n",
        "    else:\n",
        "        # Handle the case where the word is not found in the dictionary\n",
        "        # You might choose to assume one syllable or skip the word\n",
        "        return 1  # Assuming one syllable for unknown words\n",
        "def calculate_fog_index(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    words = word_tokenize(text)\n",
        "    total_words = len(words)\n",
        "    total_sentences = len(sentences)\n",
        "\n",
        "    complex_words = [word for word in words if get_syllable_count(word) >= 3]\n",
        "    total_complex_words = len(complex_words)\n",
        "\n",
        "    average_sentence_length = total_words / total_sentences\n",
        "    percentage_complex_words = (total_complex_words / total_words) * 100\n",
        "\n",
        "    fog_index = 0.4 * (average_sentence_length + percentage_complex_words)\n",
        "    return fog_index\n",
        "    def read_text_file(file_path, encodings=('utf-8', 'latin-1')):\n",
        "       for encoding in encodings:\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding=encoding, errors='replace') as file:\n",
        "                content = file.read()\n",
        "            return content\n",
        "        except UnicodeDecodeError:\n",
        "            print(f\"UnicodeDecodeError: Failed to decode using encoding {encoding}. Trying the next one.\")\n",
        "            continue\n",
        "\n",
        "    # If all encodings fail, raise an exception\n",
        "        raise UnicodeDecodeError(\"Unable to decode the file using any of the specified encodings.\")\n",
        "\n",
        "\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Stop Words/StopWords_DatesandNumbers.txt'\n",
        "text_content = read_text_file(file_path)\n",
        "\n",
        "fog_index = calculate_fog_index(text_content)\n",
        "print(f\"The Gunning Fog Index is: {fog_index:.2f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYvv06EWm4Cw",
        "outputId": "a77191e0-dd64-4c20-8dab-93225edbd7a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Package cmudict is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Gunning Fog Index is: 55.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import cmudict\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('cmudict')\n",
        "\n",
        "def get_syllable_count(word):\n",
        "    d = cmudict.dict()\n",
        "\n",
        "    # Check if the word is present in the dictionary\n",
        "    if word.lower() in d:\n",
        "        return [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]][0]\n",
        "    else:\n",
        "        # Handle the case where the word is not found in the dictionary\n",
        "        # You might choose to assume one syllable or skip the word\n",
        "        return 1  # Assuming one syllable for unknown words\n",
        "def calculate_fog_index(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    words = word_tokenize(text)\n",
        "    total_words = len(words)\n",
        "    total_sentences = len(sentences)\n",
        "\n",
        "    complex_words = [word for word in words if get_syllable_count(word) >= 3]\n",
        "    total_complex_words = len(complex_words)\n",
        "\n",
        "    average_sentence_length = total_words / total_sentences\n",
        "    percentage_complex_words = (total_complex_words / total_words) * 100\n",
        "\n",
        "    fog_index = 0.4 * (average_sentence_length + percentage_complex_words)\n",
        "    return fog_index\n",
        "\n",
        "\n",
        "\n",
        "def read_text_file(file_path, encodings=('utf-8', 'latin-1')):\n",
        "  for encoding in encodings:\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding=encoding, errors='replace') as file:\n",
        "                content = file.read()\n",
        "            return content\n",
        "        except UnicodeDecodeError:\n",
        "            print(f\"UnicodeDecodeError: Failed to decode using encoding {encoding}. Trying the next one.\")\n",
        "            continue\n",
        "\n",
        "    # If all encodings fail, raise an exception\n",
        "        raise UnicodeDecodeError(\"Unable to decode the file using any of the specified encodings.\")\n",
        "\n",
        "\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Stop Words/StopWords_Generic.txt'\n",
        "text_content = read_text_file(file_path)\n",
        "\n",
        "fog_index = calculate_fog_index(text_content)\n",
        "print(f\"The Gunning Fog Index is: {fog_index:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59lH9aJlnaLm",
        "outputId": "55d8df97-48ce-45a6-90af-d440c4d50eeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Package cmudict is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Gunning Fog Index is: 48.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import cmudict\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('cmudict')\n",
        "\n",
        "def get_syllable_count(word):\n",
        "    d = cmudict.dict()\n",
        "\n",
        "    # Check if the word is present in the dictionary\n",
        "    if word.lower() in d:\n",
        "        return [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]][0]\n",
        "    else:\n",
        "        # Handle the case where the word is not found in the dictionary\n",
        "        # You might choose to assume one syllable or skip the word\n",
        "        return 1  # Assuming one syllable for unknown words\n",
        "def calculate_fog_index(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    words = word_tokenize(text)\n",
        "    total_words = len(words)\n",
        "    total_sentences = len(sentences)\n",
        "\n",
        "    complex_words = [word for word in words if get_syllable_count(word) >= 3]\n",
        "    total_complex_words = len(complex_words)\n",
        "\n",
        "    average_sentence_length = total_words / total_sentences\n",
        "    percentage_complex_words = (total_complex_words / total_words) * 100\n",
        "\n",
        "    fog_index = 0.4 * (average_sentence_length + percentage_complex_words)\n",
        "    return fog_index\n",
        "\n",
        "\n",
        "\n",
        "def read_text_file(file_path, encodings=('utf-8', 'latin-1')):\n",
        "  for encoding in encodings:\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding=encoding, errors='replace') as file:\n",
        "                content = file.read()\n",
        "            return content\n",
        "        except UnicodeDecodeError:\n",
        "            print(f\"UnicodeDecodeError: Failed to decode using encoding {encoding}. Trying the next one.\")\n",
        "            continue\n",
        "\n",
        "    # If all encodings fail, raise an exception\n",
        "        raise UnicodeDecodeError(\"Unable to decode the file using any of the specified encodings.\")\n",
        "\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Stop Words/StopWords_GenericLong.txt'\n",
        "text_content = read_text_file(file_path)\n",
        "\n",
        "fog_index = calculate_fog_index(text_content)\n",
        "print(f\"The Gunning Fog Index is: {fog_index:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtQ5Qn5tnf_j",
        "outputId": "0e81650a-2431-413b-d440-872d93a8c2cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Package cmudict is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Gunning Fog Index is: 235.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import cmudict\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('cmudict')\n",
        "\n",
        "def get_syllable_count(word):\n",
        "    d = cmudict.dict()\n",
        "\n",
        "    # Check if the word is present in the dictionary\n",
        "    if word.lower() in d:\n",
        "        return [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]][0]\n",
        "    else:\n",
        "        # Handle the case where the word is not found in the dictionary\n",
        "        # You might choose to assume one syllable or skip the word\n",
        "        return 1  # Assuming one syllable for unknown words\n",
        "def calculate_fog_index(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    words = word_tokenize(text)\n",
        "    total_words = len(words)\n",
        "    total_sentences = len(sentences)\n",
        "\n",
        "    complex_words = [word for word in words if get_syllable_count(word) >= 3]\n",
        "    total_complex_words = len(complex_words)\n",
        "\n",
        "    average_sentence_length = total_words / total_sentences\n",
        "    percentage_complex_words = (total_complex_words / total_words) * 100\n",
        "\n",
        "    fog_index = 0.4 * (average_sentence_length + percentage_complex_words)\n",
        "    return fog_index\n",
        "\n",
        "\n",
        "\n",
        "def read_text_file(file_path, encodings=('utf-8', 'latin-1')):\n",
        "  for encoding in encodings:\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding=encoding, errors='replace') as file:\n",
        "                content = file.read()\n",
        "            return content\n",
        "        except UnicodeDecodeError:\n",
        "            print(f\"UnicodeDecodeError: Failed to decode using encoding {encoding}. Trying the next one.\")\n",
        "            continue\n",
        "            # If all encodings fail, raise an exception\n",
        "        raise UnicodeDecodeError(\"Unable to decode the file using any of the specified encodings.\")\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Stop Words/StopWords_Geographic.txt'\n",
        "\n",
        "text_content = read_text_file(file_path)\n",
        "\n",
        "fog_index = calculate_fog_index(text_content)\n",
        "print(f\"The Gunning Fog Index is: {fog_index:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8zPF5FZnp9M",
        "outputId": "f8d6596e-9e2d-4607-e137-d64e52adfe5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Package cmudict is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Gunning Fog Index is: 103.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import cmudict\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('cmudict')\n",
        "\n",
        "def get_syllable_count(word):\n",
        "    d = cmudict.dict()\n",
        "\n",
        "    # Check if the word is present in the dictionary\n",
        "    if word.lower() in d:\n",
        "        return [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]][0]\n",
        "    else:\n",
        "        # Handle the case where the word is not found in the dictionary\n",
        "        # You might choose to assume one syllable or skip the word\n",
        "        return 1  # Assuming one syllable for unknown words\n",
        "def calculate_fog_index(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    words = word_tokenize(text)\n",
        "    total_words = len(words)\n",
        "    total_sentences = len(sentences)\n",
        "\n",
        "    complex_words = [word for word in words if get_syllable_count(word) >= 3]\n",
        "    total_complex_words = len(complex_words)\n",
        "\n",
        "    average_sentence_length = total_words / total_sentences\n",
        "    percentage_complex_words = (total_complex_words / total_words) * 100\n",
        "\n",
        "    fog_index = 0.4 * (average_sentence_length + percentage_complex_words)\n",
        "    return fog_index\n",
        "def read_text_file(file_path, encodings=('utf-8', 'latin-1')):\n",
        "  for encoding in encodings:\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding=encoding, errors='replace') as file:\n",
        "                content = file.read()\n",
        "            return content\n",
        "        except UnicodeDecodeError:\n",
        "            print(f\"UnicodeDecodeError: Failed to decode using encoding {encoding}. Trying the next one.\")\n",
        "            continue\n",
        "\n",
        "    # If all encodings fail, raise an exception\n",
        "        raise UnicodeDecodeError(\"Unable to decode the file using any of the specified encodings.\")\n",
        "\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Stop Words/StopWords_Names.txt'\n",
        "text_content = read_text_file(file_path)\n",
        "\n",
        "fog_index = calculate_fog_index(text_content)\n",
        "print(f\"The Gunning Fog Index is: {fog_index:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "Nbt_dKktn2SQ",
        "outputId": "4b274879-a826-40f0-92ba-07511ccb8014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Package cmudict is already up-to-date!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-c966f80a2310>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mtext_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_text_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mfog_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_fog_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The Gunning Fog Index is: {fog_index:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-c966f80a2310>\u001b[0m in \u001b[0;36mcalculate_fog_index\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtotal_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mcomplex_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mget_syllable_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mtotal_complex_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplex_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-c966f80a2310>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtotal_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mcomplex_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mget_syllable_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mtotal_complex_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplex_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-c966f80a2310>\u001b[0m in \u001b[0;36mget_syllable_count\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_syllable_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmudict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Check if the word is present in the dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/reader/cmudict.py\u001b[0m in \u001b[0;36mdict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mlowercase\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwhose\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mare\u001b[0m \u001b[0mlists\u001b[0m \u001b[0mof\u001b[0m \u001b[0mpronunciations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/util.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pairs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mdefaultdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 8.Average Number of Words Per Sentence"
      ],
      "metadata": {
        "id": "KJjGibzvrYLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def read_text_file(file_path, encodings=('utf-8', 'latin-1')):\n",
        "    for encoding in encodings:\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding=encoding, errors='replace') as file:\n",
        "                content = file.read()\n",
        "            return content\n",
        "        except UnicodeDecodeError:\n",
        "            print(f\"UnicodeDecodeError: Failed to decode using encoding {encoding}. Trying the next one.\")\n",
        "            continue\n",
        "\n",
        "    # If all encodings fail, raise an exception\n",
        "    raise UnicodeDecodeError(\"Unable to decode the file using any of the specified encodings.\")\n",
        "\n",
        "def calculate_avg_words_per_sentence(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    total_sentences = len(sentences)\n",
        "\n",
        "    if total_sentences == 0:\n",
        "        return 0  # Avoid division by zero\n",
        "\n",
        "    total_words = sum(len(word_tokenize(sentence)) for sentence in sentences)\n",
        "    avg_words_per_sentence = total_words / total_sentences\n",
        "\n",
        "    return avg_words_per_sentence\n",
        "\n",
        "\n",
        "file_path1 = '/content/drive/MyDrive/Stop Words/StopWords_Auditor.txt'\n",
        "file_path2 = '/content/drive/MyDrive/Stop Words/StopWords_Currencies.txt'\n",
        "file_path3 = '/content/drive/MyDrive/Stop Words/StopWords_DatesandNumbers.txt'\n",
        "file_path4 = '/content/drive/MyDrive/Stop Words/StopWords_Generic.txt'\n",
        "file_path5 = '/content/drive/MyDrive/Stop Words/StopWords_GenericLong.txt'\n",
        "file_path6 = '/content/drive/MyDrive/Stop Words/StopWords_Geographic.txt'\n",
        "file_path7 = '/content/drive/MyDrive/Stop Words/StopWords_Names.txt'\n",
        "text_content1 = read_text_file(file_path1)\n",
        "text_content2 = read_text_file(file_path2)\n",
        "text_content3 = read_text_file(file_path3)\n",
        "text_content4 = read_text_file(file_path4)\n",
        "text_content5 = read_text_file(file_path5)\n",
        "text_content6 = read_text_file(file_path6)\n",
        "text_content7 = read_text_file(file_path7)\n",
        "\n",
        "avg_words_per_sentence1 = calculate_avg_words_per_sentence(text_content1)\n",
        "avg_words_per_sentence2 = calculate_avg_words_per_sentence(text_content2)\n",
        "avg_words_per_sentence3 = calculate_avg_words_per_sentence(text_content3)\n",
        "avg_words_per_sentence4 = calculate_avg_words_per_sentence(text_content4)\n",
        "avg_words_per_sentence5 = calculate_avg_words_per_sentence(text_content5)\n",
        "avg_words_per_sentence6 = calculate_avg_words_per_sentence(text_content6)\n",
        "avg_words_per_sentence7 = calculate_avg_words_per_sentence(text_content7)\n",
        "\n",
        "\n",
        "print(f\"Average words per sentence in file1: {avg_words_per_sentence1:.2f}\")\n",
        "print(f\"Average words per sentence in file2: {avg_words_per_sentence2:.2f}\")\n",
        "print(f\"Average words per sentence in file3: {avg_words_per_sentence3:.2f}\")\n",
        "print(f\"Average words per sentence in file4: {avg_words_per_sentence4:.2f}\")\n",
        "print(f\"Average words per sentence in file5: {avg_words_per_sentence5:.2f}\")\n",
        "print(f\"Average words per sentence in file6: {avg_words_per_sentence6:.2f}\")\n",
        "print(f\"Average words per sentence in file7: {avg_words_per_sentence7:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhwwf1S2oIkT",
        "outputId": "b9ef7478-ad74-49ed-b85c-a732c3ed40dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average words per sentence in file1: 8.00\n",
            "Average words per sentence in file2: 142.00\n",
            "Average words per sentence in file3: 121.00\n",
            "Average words per sentence in file4: 121.00\n",
            "Average words per sentence in file5: 572.00\n",
            "Average words per sentence in file6: 207.00\n",
            "Average words per sentence in file7: 6519.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 9.Complex Word Count"
      ],
      "metadata": {
        "id": "_e0_crW1rywf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import cmudict\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('cmudict')\n",
        "\n",
        "def count_syllables(word):\n",
        "    \"\"\"\n",
        "    Count the number of syllables in a word using the CMU Pronouncing Dictionary.\n",
        "    \"\"\"\n",
        "    d = cmudict.dict()\n",
        "\n",
        "    try:\n",
        "        return [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]][0]\n",
        "    except KeyError:\n",
        "        # Handle the case where the word is not found in the dictionary\n",
        "        return 1\n",
        "\n",
        "def is_complex(word, syllable_threshold=3):\n",
        "    \"\"\"\n",
        "    Check if a word is complex based on the number of syllables.\n",
        "    \"\"\"\n",
        "    syllable_count = count_syllables(word)\n",
        "    return syllable_count >= syllable_threshold\n",
        "\n",
        "def complex_word_count(file_path):\n",
        "    \"\"\"\n",
        "    Count the number of complex words in a text file.\n",
        "    \"\"\"\n",
        "    with open(file_path, 'r', encoding='latin-1') as file:\n",
        "        text = file.read()\n",
        "\n",
        "    words = nltk.word_tokenize(text)\n",
        "    complex_words = [word for word in words if is_complex(word)]\n",
        "\n",
        "    return len(complex_words)\n",
        "\n",
        "# Example usage:\n",
        "file_paths = ['/content/drive/MyDrive/Stop Words/StopWords_Auditor.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Currencies.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_DatesandNumbers.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Generic.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_GenericLong.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Geographic.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Names.txt']\n",
        "\n",
        "for file_path in file_paths:\n",
        " count = complex_word_count(file_path)\n",
        " print(f\"Complex word count in {file_path}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "AhZI9GOtoWBJ",
        "outputId": "0b08b56b-5f34-488b-90d6-83289587e15f"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Package cmudict is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complex word count in /content/drive/MyDrive/Stop Words/StopWords_Auditor.txt: 0\n",
            "Complex word count in /content/drive/MyDrive/Stop Words/StopWords_Currencies.txt: 70\n",
            "Complex word count in /content/drive/MyDrive/Stop Words/StopWords_DatesandNumbers.txt: 20\n",
            "Complex word count in /content/drive/MyDrive/Stop Words/StopWords_Generic.txt: 1\n",
            "Complex word count in /content/drive/MyDrive/Stop Words/StopWords_GenericLong.txt: 93\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-deb6d0b4f18c>\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m  \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplex_word_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m  \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Complex word count in {file_path}: {count}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-deb6d0b4f18c>\u001b[0m in \u001b[0;36mcomplex_word_count\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mcomplex_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplex_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-deb6d0b4f18c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mcomplex_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplex_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-deb6d0b4f18c>\u001b[0m in \u001b[0;36mis_complex\u001b[0;34m(word, syllable_threshold)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mcomplex\u001b[0m \u001b[0mbased\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0msyllables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \"\"\"\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0msyllable_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_syllables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msyllable_count\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0msyllable_threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-deb6d0b4f18c>\u001b[0m in \u001b[0;36mcount_syllables\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mCount\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0msyllables\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mword\u001b[0m \u001b[0musing\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCMU\u001b[0m \u001b[0mPronouncing\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \"\"\"\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmudict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/reader/cmudict.py\u001b[0m in \u001b[0;36mdict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mlowercase\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwhose\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mare\u001b[0m \u001b[0mlists\u001b[0m \u001b[0mof\u001b[0m \u001b[0mpronunciations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/util.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pairs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mdefaultdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/reader/util.py\u001b[0m in \u001b[0;36miterate_from\u001b[0;34m(self, start_tok)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_toknum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoknum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_blocknum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             assert isinstance(tokens, (tuple, list, AbstractLazySequence)), (\n\u001b[1;32m    308\u001b[0m                 \u001b[0;34m\"block reader %s() should return list or tuple.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/reader/cmudict.py\u001b[0m in \u001b[0;36mread_cmudict_block\u001b[0;34m(stream)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Read 100 at a time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mentries\u001b[0m  \u001b[0;31m# end of file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1110\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinebuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rewind_numchars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_chars\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rewind_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstartpos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def complex_word_count(file_path):\n",
        "    \"\"\"\n",
        "    Count the number of complex words in a text file.\n",
        "    \"\"\"\n",
        "    # Read the content of the file\n",
        "    with open(file_path, 'r', encoding='latin-1') as file:\n",
        "        file_content = file.read()\n",
        "\n",
        "    # Tokenize the text into words\n",
        "    words = nltk.word_tokenize(file_content)\n",
        "\n",
        "    # Count complex words\n",
        "    complex_words = [word for word in words if is_complex(word)]\n",
        "\n",
        "    return len(complex_words)\n",
        "\n",
        "\n",
        "file_paths = ['/content/drive/MyDrive/Stop Words/StopWords_Auditor.txt']\n",
        "\n",
        "for file_path in file_paths:\n",
        "    count = complex_word_count(file_path)\n",
        "    print(f\"Complex word count in '{file_path}': {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Leq-xYHloyTo",
        "outputId": "f6e61f73-475d-4742-c068-ba23386d3194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complex word count in '/content/drive/MyDrive/Stop Words/StopWords_Auditor.txt': 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. 10.Word Count"
      ],
      "metadata": {
        "id": "rpex3scPsR8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import chardet\n",
        "\n",
        "file_paths = ['/content/drive/MyDrive/Stop Words/StopWords_Auditor.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Currencies.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_DatesandNumbers.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Generic.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_GenericLong.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Geographic.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Names.txt']\n",
        "\n",
        "text_contents = []\n",
        "\n",
        "for file_path in file_paths:\n",
        "    with open(file_path, 'rb') as file:\n",
        "        result = chardet.detect(file.read())\n",
        "        encoding = result['encoding']\n",
        "\n",
        "    with open(file_path, 'r', encoding=encoding) as file:\n",
        "        text_contents.append(file.read())\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()\n",
        "    return len(words)\n",
        "\n",
        "word_counts = [count_words(text) for text in text_contents]\n",
        "total_word_count = sum(word_counts)\n",
        "\n",
        "print(f\"Total Word Count: {total_word_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vko68qXpPSp",
        "outputId": "b53c68ca-ece3-4011-d445-c78578e12862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Word Count: 14336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chardet\n",
        "\n",
        "file_paths = ['/content/drive/MyDrive/Stop Words/StopWords_Auditor.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Currencies.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_DatesandNumbers.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Generic.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_GenericLong.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Geographic.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Names.txt']\n",
        "\n",
        "text_contents = []\n",
        "\n",
        "for file_path in file_paths:\n",
        "    with open(file_path, 'rb') as file:\n",
        "        result = chardet.detect(file.read())\n",
        "        encoding = result['encoding']\n",
        "\n",
        "    with open(file_path, 'r', encoding=encoding) as file:\n",
        "        text_contents.append(file.read())\n"
      ],
      "metadata": {
        "id": "b2obBCtrphJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. 11.Syllable Count per word"
      ],
      "metadata": {
        "id": "AEHCh7lctcDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install textstat nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NdRt8MQDqjc",
        "outputId": "45997a8e-7d39-46be-a9f5-26f3bd97e8d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textstat\n",
            "  Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/105.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m92.2/105.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Collecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.14.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Installing collected packages: pyphen, textstat\n",
            "Successfully installed pyphen-0.14.0 textstat-0.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import textstat\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def syllable_count_per_word(file_path, encoding='utf-8'):\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding=encoding) as file:\n",
        "            file_content = file.read()\n",
        "    except UnicodeDecodeError:\n",
        "        print(f\"Failed to read {file_path} with encoding {encoding}\")\n",
        "        return 0\n",
        "\n",
        "    # Tokenize the text into words\n",
        "    words = word_tokenize(file_content)\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "    # Calculate the syllable count for each word\n",
        "    syllable_counts = [textstat.syllable_count(word) for word in words]\n",
        "\n",
        "    # Calculate the average syllable count per word\n",
        "    if len(syllable_counts) > 0:\n",
        "        avg_syllables_per_word = sum(syllable_counts) / len(syllable_counts)\n",
        "        return avg_syllables_per_word\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# List of file paths\n",
        "file_paths = ['/content/drive/MyDrive/Stop Words/StopWords_Auditor.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Currencies.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_DatesandNumbers.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Generic.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_GenericLong.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Geographic.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Names.txt']\n",
        "# Calculate and print the average syllable count per word for each file\n",
        "for file_path in file_paths:\n",
        "    avg_syllables_per_word = syllable_count_per_word(file_path)\n",
        "    print(f\"Average syllable count per word in {file_path}: {avg_syllables_per_word:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW9VJ0nIELTq",
        "outputId": "7dba076f-a218-457c-9997-5763c7a28799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average syllable count per word in /content/drive/MyDrive/Stop Words/StopWords_Auditor.txt: 2.50\n",
            "Failed to read /content/drive/MyDrive/Stop Words/StopWords_Currencies.txt with encoding utf-8\n",
            "Average syllable count per word in /content/drive/MyDrive/Stop Words/StopWords_Currencies.txt: 0.00\n",
            "Average syllable count per word in /content/drive/MyDrive/Stop Words/StopWords_DatesandNumbers.txt: 1.56\n",
            "Average syllable count per word in /content/drive/MyDrive/Stop Words/StopWords_Generic.txt: 1.00\n",
            "Average syllable count per word in /content/drive/MyDrive/Stop Words/StopWords_GenericLong.txt: 1.73\n",
            "Average syllable count per word in /content/drive/MyDrive/Stop Words/StopWords_Geographic.txt: 1.98\n",
            "Average syllable count per word in /content/drive/MyDrive/Stop Words/StopWords_Names.txt: 1.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. 12. Personal Pronouns"
      ],
      "metadata": {
        "id": "p3yVRCv2soR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "file_paths = ['/content/drive/MyDrive/Stop Words/StopWords_Auditor.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Currencies.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_DatesandNumbers.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Generic.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_GenericLong.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Geographic.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Names.txt']\n",
        "\n",
        "import chardet\n",
        "\n",
        "file_contents = []\n",
        "for file_path in file_paths:\n",
        "    with open(file_path, 'rb') as file:\n",
        "        result = chardet.detect(file.read())\n",
        "    encoding = result['encoding']\n",
        "    with open(file_path, 'r', encoding=encoding) as file:\n",
        "        file_contents.append(file.read())\n",
        "\n",
        "\n",
        "personal_pronouns = ['I', 'me', 'my', 'mine', 'myself', 'you', 'your', 'yours', 'yourself',\n",
        "                    'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself',\n",
        "                    'it', 'its', 'itself', 'we', 'us', 'our', 'ours', 'ourselves',\n",
        "                    'they', 'them', 'their', 'theirs', 'themselves']\n",
        "\n",
        "def count_personal_pronouns(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tagged_words = pos_tag(tokens)\n",
        "    pronoun_count = sum(1 for word, pos in tagged_words if pos == 'PRP' and word.lower() in personal_pronouns)\n",
        "    return pronoun_count\n",
        "\n",
        "personal_pronoun_counts = [count_personal_pronouns(text) for text in text_contents]\n",
        "total_personal_pronoun_count = sum(personal_pronoun_counts)\n",
        "\n",
        "print(f\"Total Personal Pronoun Count: {total_personal_pronoun_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iERHIKHJpoT_",
        "outputId": "50ddb061-b57b-4bc5-f019-2ba8b8ceeefb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Personal Pronoun Count: 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. 13. Average Word Length"
      ],
      "metadata": {
        "id": "0m8_7IQDs3Lr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_average_word_length(text):\n",
        "    words = text.split()\n",
        "    total_word_length = sum(len(word) for word in words)\n",
        "    return total_word_length / len(words) if len(words) > 0 else 0\n",
        "\n",
        "# List of seven text file names\n",
        "file_names = ['/content/drive/MyDrive/Stop Words/StopWords_Auditor.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Currencies.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_DatesandNumbers.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Generic.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_GenericLong.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Geographic.txt',\n",
        "              '/content/drive/MyDrive/Stop Words/StopWords_Names.txt']\n",
        "\n",
        "# List to store individual average word lengths\n",
        "individual_avg_lengths = []\n",
        "\n",
        "# Iterate over each text file\n",
        "for file_name in file_names:\n",
        "    file_path = file_name  # If files are in the same directory as the script\n",
        "\n",
        "    # Read the content of the file\n",
        "    with open(file_path, 'r', encoding='latin-1') as file:\n",
        "        file_content = file.read()\n",
        "\n",
        "    # Calculate the average word length for each file\n",
        "    avg_length = calculate_average_word_length(file_content)\n",
        "    print(f\"Average word length in '{file_name}': {avg_length:.2f}\")\n",
        "\n",
        "    # Store individual average word lengths for later use\n",
        "    individual_avg_lengths.append(avg_length)\n",
        "\n",
        "# Calculate and print the overall average word length\n",
        "overall_avg_length = sum(individual_avg_lengths) / len(individual_avg_lengths) if len(individual_avg_lengths) > 0 else 0\n",
        "print(f\"\\nOverall average word length: {overall_avg_length:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWSv5-aPppiI",
        "outputId": "6fe8dd12-db15-40f8-bef2-6b00ec6a45ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average word length in '/content/drive/MyDrive/Stop Words/StopWords_Auditor.txt': 9.00\n",
            "Average word length in '/content/drive/MyDrive/Stop Words/StopWords_Currencies.txt': 4.57\n",
            "Average word length in '/content/drive/MyDrive/Stop Words/StopWords_DatesandNumbers.txt': 4.95\n",
            "Average word length in '/content/drive/MyDrive/Stop Words/StopWords_Generic.txt': 3.98\n",
            "Average word length in '/content/drive/MyDrive/Stop Words/StopWords_GenericLong.txt': 5.29\n",
            "Average word length in '/content/drive/MyDrive/Stop Words/StopWords_Geographic.txt': 6.81\n",
            "Average word length in '/content/drive/MyDrive/Stop Words/StopWords_Names.txt': 6.19\n",
            "\n",
            "Overall average word length: 5.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data Extraction"
      ],
      "metadata": {
        "id": "PnhfqaBw2CpE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  1. All input variables in \"Input.xlsx\""
      ],
      "metadata": {
        "id": "FBeVLsp92I6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel('/content/drive/MyDrive/Input.xlsx')"
      ],
      "metadata": {
        "id": "fBUpWhvc4iJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "sL9I7agp7Zdo",
        "outputId": "8656f64b-7985-4073-b852-1144ede9f039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  URL  \\\n",
              "0   https://insights.blackcoffer.com/rising-it-cit...   \n",
              "1   https://insights.blackcoffer.com/rising-it-cit...   \n",
              "2   https://insights.blackcoffer.com/internet-dema...   \n",
              "3   https://insights.blackcoffer.com/rise-of-cyber...   \n",
              "4   https://insights.blackcoffer.com/ott-platform-...   \n",
              "..                                                ...   \n",
              "95  https://insights.blackcoffer.com/what-is-the-r...   \n",
              "96  https://insights.blackcoffer.com/impact-of-cov...   \n",
              "97  https://insights.blackcoffer.com/contribution-...   \n",
              "98  https://insights.blackcoffer.com/how-covid-19-...   \n",
              "99  https://insights.blackcoffer.com/how-will-covi...   \n",
              "\n",
              "                                      Analysis Result  \n",
              "0   [('cities', 31), ('impact', 21), ('market', 20...  \n",
              "1   [('cities', 35), ('august', 18), ('impact', 17...  \n",
              "2   [('internet', 25), ('august', 20), ('demand', ...  \n",
              "3   [('data', 18), ('august', 18), ('cybercrime', ...  \n",
              "4   [('ott', 25), ('platforms', 19), ('august', 18...  \n",
              "..                                                ...  \n",
              "95  [('august', 17), ('think', 13), ('due', 12), (...  \n",
              "96  [('impact', 18), ('august', 17), ('employees',...  \n",
              "97  [('august', 17), ('handicrafts', 14), ('think'...  \n",
              "98  [('august', 24), ('online', 22), ('think', 16)...  \n",
              "99  [('august', 24), ('think', 16), ('impact', 13)...  \n",
              "\n",
              "[100 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58195805-613c-4c34-9bb9-20e9813ba466\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URL</th>\n",
              "      <th>Analysis Result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
              "      <td>[('cities', 31), ('impact', 21), ('market', 20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
              "      <td>[('cities', 35), ('august', 18), ('impact', 17...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
              "      <td>[('internet', 25), ('august', 20), ('demand', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
              "      <td>[('data', 18), ('august', 18), ('cybercrime', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
              "      <td>[('ott', 25), ('platforms', 19), ('august', 18...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
              "      <td>[('august', 17), ('think', 13), ('due', 12), (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
              "      <td>[('impact', 18), ('august', 17), ('employees',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
              "      <td>[('august', 17), ('handicrafts', 14), ('think'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>https://insights.blackcoffer.com/how-covid-19-...</td>\n",
              "      <td>[('august', 24), ('online', 22), ('think', 16)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>https://insights.blackcoffer.com/how-will-covi...</td>\n",
              "      <td>[('august', 24), ('think', 16), ('impact', 13)...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58195805-613c-4c34-9bb9-20e9813ba466')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-58195805-613c-4c34-9bb9-20e9813ba466 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-58195805-613c-4c34-9bb9-20e9813ba466');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1213d75f-f1a7-40cd-ba14-a7bff0ab0de4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1213d75f-f1a7-40cd-ba14-a7bff0ab0de4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1213d75f-f1a7-40cd-ba14-a7bff0ab0de4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_dc7a3398-37cd-4b35-9b01-83c9296a65a4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_dc7a3398-37cd-4b35-9b01-83c9296a65a4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Read the Excel file\n",
        "excel_file = \"/content/drive/MyDrive/Input.xlsx\"\n",
        "df = pd.read_excel(excel_file)\n",
        "\n",
        "# Iterate through rows in the DataFrame\n",
        "for index, row in df.iterrows():\n",
        "    url_id = row['Analysis Result']\n",
        "    url = row['URL']\n",
        "\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        html_content = response.text\n",
        "\n",
        "        # Use BeautifulSoup to parse HTML and extract article text\n",
        "        soup = BeautifulSoup(html_content, 'html.parser')\n",
        "        article_text = \"\"\n",
        "\n",
        "        # Customize this part based on the structure of the HTML\n",
        "        # You might need to inspect the HTML structure of the pages and adapt this code\n",
        "        # to extract the relevant article text based on the actual structure\n",
        "        article_elements = soup.find_all('p')\n",
        "        for element in article_elements:\n",
        "            article_text += element.get_text() + \"\\n\"\n",
        "\n",
        "        # Save the extracted article in a text file\n",
        "        output_file = f\"{url_id}.txt\"\n",
        "        with open(output_file, 'w', encoding='utf-8') as file:\n",
        "            file.write(article_text)\n",
        "\n",
        "        print(f\"Article for URL_ID {url_id} saved to {output_file}\")\n",
        "    else:\n",
        "        print(f\"Failed to retrieve content for URL_ID {url_id}\")\n",
        "\n",
        "print(\"Extraction and saving process completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2iLCZSC2OEU",
        "outputId": "dfec0d67-b4e4-4811-f3e5-77afa0d59e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Article for URL_ID [('cities', 31), ('impact', 21), ('market', 20), ('august', 18), ('companies', 18), ('economy', 16), ('rising', 14), ('infrastructure', 14), ('people', 14), ('environment', 13)] saved to [('cities', 31), ('impact', 21), ('market', 20), ('august', 18), ('companies', 18), ('economy', 16), ('rising', 14), ('infrastructure', 14), ('people', 14), ('environment', 13)].txt\n",
            "Article for URL_ID [('cities', 35), ('august', 18), ('impact', 17), ('technology', 16), ('data', 15), ('environment', 13), ('life', 13), ('think', 13), ('economy', 12), ('infrastructure', 12)] saved to [('cities', 35), ('august', 18), ('impact', 17), ('technology', 16), ('data', 15), ('environment', 13), ('life', 13), ('think', 13), ('economy', 12), ('infrastructure', 12)].txt\n",
            "Article for URL_ID [('internet', 25), ('august', 20), ('demand', 19), ('infrastructure', 19), ('communication', 18), ('impact', 18), ('data', 17), ('think', 13), ('future', 13), ('connectivity', 12)] saved to [('internet', 25), ('august', 20), ('demand', 19), ('infrastructure', 19), ('communication', 18), ('impact', 18), ('data', 17), ('think', 13), ('future', 13), ('connectivity', 12)].txt\n",
            "Article for URL_ID [('data', 18), ('august', 18), ('cybercrime', 16), ('infrastructure', 15), ('think', 13), ('impact', 13), ('digital', 12), ('future', 11), ('economy', 10), ('success', 9)] saved to [('data', 18), ('august', 18), ('cybercrime', 16), ('infrastructure', 15), ('think', 13), ('impact', 13), ('digital', 12), ('future', 11), ('economy', 10), ('success', 9)].txt\n",
            "Article for URL_ID [('ott', 25), ('platforms', 19), ('august', 18), ('impact', 17), ('entertainment', 13), ('think', 13), ('content', 13), ('infrastructure', 10), ('data', 10), ('industry', 9)] saved to [('ott', 25), ('platforms', 19), ('august', 18), ('impact', 17), ('entertainment', 13), ('think', 13), ('content', 13), ('infrastructure', 10), ('data', 10), ('industry', 9)].txt\n",
            "Article for URL_ID [('content', 40), ('platforms', 39), ('ott', 36), ('entertainment', 23), ('impact', 19), ('august', 19), ('rise', 17), ('traditional', 16), ('industry', 14), ('think', 13)] saved to [('content', 40), ('platforms', 39), ('ott', 36), ('entertainment', 23), ('impact', 19), ('august', 19), ('rise', 17), ('traditional', 16), ('industry', 14), ('think', 13)].txt\n",
            "Article for URL_ID [('data', 22), ('cybercrime', 19), ('august', 18), ('cyber', 15), ('think', 13), ('password', 11), ('impact', 11), ('security', 11), ('success', 10), ('infrastructure', 10)] saved to [('data', 22), ('cybercrime', 19), ('august', 18), ('cyber', 15), ('think', 13), ('password', 11), ('impact', 11), ('security', 11), ('success', 10), ('infrastructure', 10)].txt\n",
            "Article for URL_ID [('internet', 24), ('august', 18), ('communication', 17), ('impact', 15), ('think', 14), ('infrastructure', 13), ('data', 13), ('rise', 12), ('demand', 12), ('year', 11)] saved to [('internet', 24), ('august', 18), ('communication', 17), ('impact', 15), ('think', 14), ('infrastructure', 13), ('data', 13), ('rise', 12), ('demand', 12), ('year', 11)].txt\n",
            "Article for URL_ID [('cybercrime', 31), ('data', 24), ('august', 19), ('cyber', 17), ('impact', 15), ('rise', 13), ('year', 13), ('think', 13), ('infrastructure', 13), ('financial', 12)] saved to [('cybercrime', 31), ('data', 24), ('august', 19), ('cyber', 17), ('impact', 15), ('rise', 13), ('year', 13), ('think', 13), ('infrastructure', 13), ('financial', 12)].txt\n",
            "Article for URL_ID [('cybercrime', 92), ('cybercriminals', 31), ('attacks', 26), ('businesses', 25), ('data', 24), ('impact', 23), ('help', 21), ('protect', 20), ('infrastructure', 19), ('august', 19)] saved to [('cybercrime', 92), ('cybercriminals', 31), ('attacks', 26), ('businesses', 25), ('data', 24), ('impact', 23), ('help', 21), ('protect', 20), ('infrastructure', 19), ('august', 19)].txt\n",
            "Article for URL_ID [('internet', 45), ('data', 25), ('august', 20), ('infrastructure', 16), ('impact', 15), ('demand', 13), ('year', 13), ('think', 13), ('digital', 13), ('cities', 11)] saved to [('internet', 45), ('data', 25), ('august', 20), ('infrastructure', 16), ('impact', 15), ('demand', 13), ('year', 13), ('think', 13), ('digital', 13), ('cities', 11)].txt\n",
            "Article for URL_ID [('telemedicine', 62), ('healthcare', 54), ('patients', 41), ('care', 28), ('medical', 18), ('rise', 17), ('impact', 17), ('help', 17), ('august', 17), ('providers', 15)] saved to [('telemedicine', 62), ('healthcare', 54), ('patients', 41), ('care', 28), ('medical', 18), ('rise', 17), ('impact', 17), ('help', 17), ('august', 17), ('providers', 15)].txt\n",
            "Article for URL_ID [('healthcare', 20), ('impact', 18), ('august', 18), ('think', 14), ('data', 13), ('year', 12), ('infrastructure', 10), ('use', 10), ('potential', 10), ('success', 9)] saved to [('healthcare', 20), ('impact', 18), ('august', 18), ('think', 14), ('data', 13), ('year', 12), ('infrastructure', 10), ('use', 10), ('potential', 10), ('success', 9)].txt\n",
            "Article for URL_ID [('august', 24), ('impact', 18), ('think', 15), ('year', 14), ('healthcare', 14), ('data', 13), ('pandemic', 13), ('infrastructure', 12), ('rising', 12), ('also', 12)] saved to [('august', 24), ('impact', 18), ('think', 15), ('year', 14), ('healthcare', 14), ('data', 13), ('pandemic', 13), ('infrastructure', 12), ('rising', 12), ('also', 12)].txt\n",
            "Article for URL_ID [('care', 19), ('august', 18), ('impact', 17), ('health', 16), ('consumer', 15), ('telehealth', 15), ('think', 14), ('healthcare', 14), ('patients', 13), ('virtual', 13)] saved to [('care', 19), ('august', 18), ('impact', 17), ('health', 16), ('consumer', 15), ('telehealth', 15), ('think', 14), ('healthcare', 14), ('patients', 13), ('virtual', 13)].txt\n",
            "Article for URL_ID [('care', 19), ('august', 18), ('impact', 16), ('consumer', 15), ('telehealth', 15), ('health', 15), ('think', 14), ('healthcare', 14), ('data', 13), ('patients', 13)] saved to [('care', 19), ('august', 18), ('impact', 16), ('consumer', 15), ('telehealth', 15), ('health', 15), ('think', 14), ('healthcare', 14), ('data', 13), ('patients', 13)].txt\n",
            "Article for URL_ID [('chatbots', 27), ('customer', 25), ('august', 19), ('impact', 18), ('data', 14), ('think', 13), ('chatbot', 13), ('year', 11), ('insights', 10), ('infrastructure', 10)] saved to [('chatbots', 27), ('customer', 25), ('august', 19), ('impact', 18), ('data', 14), ('think', 13), ('chatbot', 13), ('year', 11), ('insights', 10), ('infrastructure', 10)].txt\n",
            "Article for URL_ID [('august', 17), ('health', 16), ('impact', 14), ('healthcare', 14), ('think', 13), ('future', 12), ('year', 11), ('consumer', 11), ('data', 11), ('infrastructure', 10)] saved to [('august', 17), ('health', 16), ('impact', 14), ('healthcare', 14), ('think', 13), ('future', 12), ('year', 11), ('consumer', 11), ('data', 11), ('infrastructure', 10)].txt\n",
            "Article for URL_ID [('marketing', 50), ('business', 21), ('consumer', 20), ('august', 19), ('businesses', 17), ('impact', 17), ('consumers', 13), ('think', 13), ('market', 13), ('product', 12)] saved to [('marketing', 50), ('business', 21), ('consumer', 20), ('august', 19), ('businesses', 17), ('impact', 17), ('consumers', 13), ('think', 13), ('market', 13), ('product', 12)].txt\n",
            "Article for URL_ID [('market', 27), ('august', 24), ('value', 22), ('think', 16), ('product', 15), ('advertisement', 13), ('impact', 13), ('increase', 12), ('infrastructure', 12), ('company', 12)] saved to [('market', 27), ('august', 24), ('value', 22), ('think', 16), ('product', 15), ('advertisement', 13), ('impact', 13), ('increase', 12), ('infrastructure', 12), ('company', 12)].txt\n",
            "Article for URL_ID [('marketing', 30), ('august', 19), ('advertising', 16), ('think', 13), ('impact', 13), ('society', 11), ('infrastructure', 10), ('data', 10), ('economy', 10), ('environment', 10)] saved to [('marketing', 30), ('august', 19), ('advertising', 16), ('think', 13), ('impact', 13), ('society', 11), ('infrastructure', 10), ('data', 10), ('economy', 10), ('environment', 10)].txt\n",
            "Article for URL_ID [('august', 17), ('think', 14), ('infrastructure', 11), ('impact', 11), ('success', 10), ('market', 10), ('environment', 10), ('data', 9), ('password', 9), ('cities', 9)] saved to [('august', 17), ('think', 14), ('infrastructure', 11), ('impact', 11), ('success', 10), ('market', 10), ('environment', 10), ('data', 9), ('password', 9), ('cities', 9)].txt\n",
            "Article for URL_ID [('cities', 29), ('economy', 18), ('infrastructure', 17), ('august', 17), ('impact', 14), ('environment', 14), ('think', 13), ('world', 13), ('india', 13), ('urban', 13)] saved to [('cities', 29), ('economy', 18), ('infrastructure', 17), ('august', 17), ('impact', 14), ('environment', 14), ('think', 13), ('world', 13), ('india', 13), ('urban', 13)].txt\n",
            "Article for URL_ID [('impact', 17), ('august', 17), ('think', 15), ('ott', 13), ('infrastructure', 11), ('year', 10), ('success', 10), ('data', 10), ('cities', 10), ('economy', 10)] saved to [('impact', 17), ('august', 17), ('think', 15), ('ott', 13), ('infrastructure', 11), ('year', 10), ('success', 10), ('data', 10), ('cities', 10), ('economy', 10)].txt\n",
            "Article for URL_ID [('august', 19), ('impact', 15), ('india', 15), ('think', 14), ('infrastructure', 12), ('vehicles', 11), ('government', 11), ('consumer', 10), ('rising', 10), ('cities', 10)] saved to [('august', 19), ('impact', 15), ('india', 15), ('think', 14), ('infrastructure', 12), ('vehicles', 11), ('government', 11), ('consumer', 10), ('rising', 10), ('cities', 10)].txt\n",
            "Article for URL_ID [('electric', 21), ('august', 19), ('impact', 16), ('think', 13), ('infrastructure', 12), ('vehicles', 12), ('year', 10), ('consumer', 10), ('cities', 10), ('environment', 10)] saved to [('electric', 21), ('august', 19), ('impact', 16), ('think', 13), ('infrastructure', 12), ('vehicles', 12), ('year', 10), ('consumer', 10), ('cities', 10), ('environment', 10)].txt\n",
            "Article for URL_ID [('world', 20), ('impact', 18), ('august', 18), ('vehicles', 18), ('electric', 17), ('also', 17), ('economy', 13), ('think', 13), ('future', 13), ('year', 12)] saved to [('world', 20), ('impact', 18), ('august', 18), ('vehicles', 18), ('electric', 17), ('also', 17), ('economy', 13), ('think', 13), ('future', 13), ('year', 12)].txt\n",
            "Article for URL_ID [('health', 22), ('healthcare', 20), ('august', 18), ('data', 17), ('impact', 15), ('future', 15), ('think', 13), ('infrastructure', 11), ('year', 10), ('economy', 10)] saved to [('health', 22), ('healthcare', 20), ('august', 18), ('data', 17), ('impact', 15), ('future', 15), ('think', 13), ('infrastructure', 11), ('year', 10), ('economy', 10)].txt\n",
            "Article for URL_ID [('ai', 28), ('data', 26), ('august', 24), ('think', 16), ('patient', 15), ('healthcare', 14), ('impact', 13), ('infrastructure', 12), ('learning', 11), ('help', 11)] saved to [('ai', 28), ('data', 26), ('august', 24), ('think', 16), ('patient', 15), ('healthcare', 14), ('impact', 13), ('infrastructure', 12), ('learning', 11), ('help', 11)].txt\n",
            "Article for URL_ID [('ai', 23), ('machines', 19), ('august', 17), ('skills', 16), ('think', 15), ('jobs', 14), ('data', 13), ('humans', 13), ('intelligence', 12), ('impact', 12)] saved to [('ai', 23), ('machines', 19), ('august', 17), ('skills', 16), ('think', 15), ('jobs', 14), ('data', 13), ('humans', 13), ('intelligence', 12), ('impact', 12)].txt\n",
            "Article for URL_ID [('data', 29), ('machine', 29), ('learning', 27), ('august', 17), ('information', 17), ('think', 14), ('impact', 12), ('future', 11), ('consumer', 10), ('infrastructure', 10)] saved to [('data', 29), ('machine', 29), ('learning', 27), ('august', 17), ('information', 17), ('think', 14), ('impact', 12), ('future', 11), ('consumer', 10), ('infrastructure', 10)].txt\n",
            "Article for URL_ID [('ai', 36), ('human', 28), ('intelligence', 21), ('think', 17), ('august', 17), ('machine', 16), ('data', 15), ('future', 13), ('able', 13), ('infrastructure', 11)] saved to [('ai', 36), ('human', 28), ('intelligence', 21), ('think', 17), ('august', 17), ('machine', 16), ('data', 15), ('future', 13), ('able', 13), ('infrastructure', 11)].txt\n",
            "Article for URL_ID [('intelligence', 20), ('artificial', 18), ('august', 17), ('us', 15), ('think', 15), ('data', 15), ('future', 13), ('humans', 13), ('machines', 13), ('work', 12)] saved to [('intelligence', 20), ('artificial', 18), ('august', 17), ('us', 15), ('think', 15), ('data', 15), ('future', 13), ('humans', 13), ('machines', 13), ('work', 12)].txt\n",
            "Article for URL_ID [('think', 20), ('humans', 19), ('august', 18), ('machines', 17), ('data', 15), ('impact', 13), ('machine', 11), ('future', 11), ('work', 11), ('infrastructure', 11)] saved to [('think', 20), ('humans', 19), ('august', 18), ('machines', 17), ('data', 15), ('impact', 13), ('machine', 11), ('future', 11), ('work', 11), ('infrastructure', 11)].txt\n",
            "Article for URL_ID [('machines', 35), ('humans', 22), ('august', 18), ('think', 15), ('future', 13), ('work', 12), ('data', 12), ('infrastructure', 10), ('impact', 10), ('together', 9)] saved to [('machines', 35), ('humans', 22), ('august', 18), ('think', 15), ('future', 13), ('work', 12), ('data', 12), ('infrastructure', 10), ('impact', 10), ('together', 9)].txt\n",
            "Failed to retrieve content for URL_ID [('august', 23), ('think', 18), ('impact', 11), ('infrastructure', 10), ('success', 9), ('password', 9), ('stories', 8), ('consumer', 8), ('data', 8), ('rising', 8)]\n",
            "Article for URL_ID [('machine', 21), ('learning', 21), ('data', 17), ('august', 17), ('think', 13), ('algorithm', 13), ('business', 12), ('impact', 11), ('infrastructure', 10), ('success', 9)] saved to [('machine', 21), ('learning', 21), ('data', 17), ('august', 17), ('think', 13), ('algorithm', 13), ('business', 12), ('impact', 11), ('infrastructure', 10), ('success', 9)].txt\n",
            "Article for URL_ID [('ai', 46), ('data', 22), ('impact', 19), ('learning', 17), ('august', 17), ('think', 15), ('future', 15), ('deep', 12), ('many', 12), ('resume', 12)] saved to [('ai', 46), ('data', 22), ('impact', 19), ('learning', 17), ('august', 17), ('think', 15), ('future', 15), ('deep', 12), ('many', 12), ('resume', 12)].txt\n",
            "Article for URL_ID [('data', 39), ('computer', 22), ('files', 19), ('august', 17), ('twitter', 16), ('cloud', 14), ('information', 14), ('think', 13), ('password', 11), ('impact', 11)] saved to [('data', 39), ('computer', 22), ('files', 19), ('august', 17), ('twitter', 16), ('cloud', 14), ('information', 14), ('think', 13), ('password', 11), ('impact', 11)].txt\n",
            "Article for URL_ID [('machine', 23), ('learning', 22), ('data', 18), ('august', 17), ('think', 14), ('financial', 14), ('impact', 13), ('customer', 12), ('future', 11), ('banking', 10)] saved to [('machine', 23), ('learning', 22), ('data', 18), ('august', 17), ('think', 14), ('financial', 14), ('impact', 13), ('customer', 12), ('future', 11), ('banking', 10)].txt\n",
            "Article for URL_ID [('ai', 27), ('future', 20), ('data', 20), ('august', 17), ('impact', 15), ('think', 15), ('jobs', 15), ('insights', 12), ('human', 11), ('infrastructure', 10)] saved to [('ai', 27), ('future', 20), ('data', 20), ('august', 17), ('impact', 15), ('think', 15), ('jobs', 15), ('insights', 12), ('human', 11), ('infrastructure', 10)].txt\n",
            "Article for URL_ID [('future', 25), ('technology', 20), ('ai', 18), ('august', 18), ('humans', 18), ('think', 17), ('data', 17), ('would', 17), ('impact', 13), ('us', 13)] saved to [('future', 25), ('technology', 20), ('ai', 18), ('august', 18), ('humans', 18), ('think', 17), ('data', 17), ('would', 17), ('impact', 13), ('us', 13)].txt\n",
            "Article for URL_ID [('ai', 51), ('august', 24), ('intelligence', 17), ('impact', 17), ('think', 16), ('artificial', 14), ('jobs', 13), ('infrastructure', 12), ('data', 12), ('business', 12)] saved to [('ai', 51), ('august', 24), ('intelligence', 17), ('impact', 17), ('think', 16), ('artificial', 14), ('jobs', 13), ('infrastructure', 12), ('data', 12), ('business', 12)].txt\n",
            "Article for URL_ID [('august', 18), ('think', 14), ('impact', 12), ('infrastructure', 11), ('ai', 11), ('success', 10), ('environment', 10), ('conversational', 10), ('insights', 9), ('data', 9)] saved to [('august', 18), ('think', 14), ('impact', 12), ('infrastructure', 11), ('ai', 11), ('success', 10), ('environment', 10), ('conversational', 10), ('insights', 9), ('data', 9)].txt\n",
            "Article for URL_ID [('ai', 28), ('data', 21), ('think', 19), ('august', 18), ('impact', 15), ('future', 14), ('people', 14), ('jobs', 13), ('like', 12), ('infrastructure', 11)] saved to [('ai', 28), ('data', 21), ('think', 19), ('august', 18), ('impact', 15), ('future', 14), ('people', 14), ('jobs', 13), ('like', 12), ('infrastructure', 11)].txt\n",
            "Article for URL_ID [('marketing', 32), ('online', 24), ('august', 18), ('think', 15), ('advertising', 14), ('infrastructure', 12), ('services', 12), ('media', 12), ('data', 11), ('impact', 11)] saved to [('marketing', 32), ('online', 24), ('august', 18), ('think', 15), ('advertising', 14), ('infrastructure', 12), ('services', 12), ('media', 12), ('data', 11), ('impact', 11)].txt\n",
            "Article for URL_ID [('advertising', 35), ('august', 20), ('think', 14), ('industry', 12), ('data', 11), ('impact', 11), ('infrastructure', 10), ('content', 10), ('success', 9), ('consumer', 9)] saved to [('advertising', 35), ('august', 20), ('think', 14), ('industry', 12), ('data', 11), ('impact', 11), ('infrastructure', 10), ('content', 10), ('success', 9), ('consumer', 9)].txt\n",
            "Article for URL_ID [('data', 23), ('august', 18), ('impact', 13), ('think', 13), ('analysis', 13), ('infrastructure', 11), ('analytics', 9), ('success', 9), ('password', 9), ('life', 9)] saved to [('data', 23), ('august', 18), ('impact', 13), ('think', 13), ('analysis', 13), ('infrastructure', 11), ('analytics', 9), ('success', 9), ('password', 9), ('life', 9)].txt\n",
            "Failed to retrieve content for URL_ID [('august', 23), ('think', 18), ('impact', 11), ('infrastructure', 10), ('success', 9), ('password', 9), ('stories', 8), ('consumer', 8), ('data', 8), ('rising', 8)]\n",
            "Article for URL_ID [('august', 17), ('data', 15), ('impact', 14), ('environment', 14), ('think', 13), ('pandemic', 11), ('cities', 11), ('economy', 11), ('people', 11), ('future', 10)] saved to [('august', 17), ('data', 15), ('impact', 14), ('environment', 14), ('think', 13), ('pandemic', 11), ('cities', 11), ('economy', 11), ('people', 11), ('future', 10)].txt\n",
            "Article for URL_ID [('data', 22), ('august', 19), ('think', 14), ('analytics', 12), ('impact', 12), ('ai', 11), ('infrastructure', 10), ('city', 10), ('success', 9), ('password', 9)] saved to [('data', 22), ('august', 19), ('think', 14), ('analytics', 12), ('impact', 12), ('ai', 11), ('infrastructure', 10), ('city', 10), ('success', 9), ('password', 9)].txt\n",
            "Article for URL_ID [('data', 51), ('intelligence', 28), ('ai', 22), ('statistics', 22), ('august', 17), ('think', 15), ('learning', 14), ('aim', 14), ('machine', 12), ('human', 12)] saved to [('data', 51), ('intelligence', 28), ('ai', 22), ('statistics', 22), ('august', 17), ('think', 15), ('learning', 14), ('aim', 14), ('machine', 12), ('human', 12)].txt\n",
            "Article for URL_ID [('data', 36), ('python', 27), ('august', 17), ('science', 16), ('think', 14), ('infrastructure', 10), ('impact', 10), ('success', 9), ('password', 9), ('environment', 9)] saved to [('data', 36), ('python', 27), ('august', 17), ('science', 16), ('think', 14), ('infrastructure', 10), ('impact', 10), ('success', 9), ('password', 9), ('environment', 9)].txt\n",
            "Article for URL_ID [('august', 18), ('google', 15), ('think', 14), ('data', 14), ('impact', 12), ('heart', 10), ('infrastructure', 10), ('success', 9), ('password', 9), ('respiratory', 8)] saved to [('august', 18), ('google', 15), ('think', 14), ('data', 14), ('impact', 12), ('heart', 10), ('infrastructure', 10), ('success', 9), ('password', 9), ('respiratory', 8)].txt\n",
            "Article for URL_ID [('mobile', 32), ('apps', 22), ('app', 18), ('august', 17), ('future', 14), ('think', 13), ('market', 13), ('data', 13), ('infrastructure', 10), ('development', 10)] saved to [('mobile', 32), ('apps', 22), ('app', 18), ('august', 17), ('future', 14), ('think', 13), ('market', 13), ('data', 13), ('infrastructure', 10), ('development', 10)].txt\n",
            "Article for URL_ID [('august', 19), ('data', 17), ('ai', 16), ('think', 14), ('health', 12), ('impact', 12), ('insights', 10), ('infrastructure', 10), ('medical', 10), ('success', 9)] saved to [('august', 19), ('data', 17), ('ai', 16), ('think', 14), ('health', 12), ('impact', 12), ('insights', 10), ('infrastructure', 10), ('medical', 10), ('success', 9)].txt\n",
            "Article for URL_ID [('august', 17), ('patients', 15), ('think', 13), ('telemedicine', 12), ('infrastructure', 10), ('impact', 10), ('success', 9), ('data', 9), ('password', 9), ('insights', 8)] saved to [('august', 17), ('patients', 15), ('think', 13), ('telemedicine', 12), ('infrastructure', 10), ('impact', 10), ('success', 9), ('data', 9), ('password', 9), ('insights', 8)].txt\n",
            "Article for URL_ID [('august', 17), ('think', 14), ('data', 13), ('future', 11), ('infrastructure', 10), ('life', 10), ('success', 9), ('password', 9), ('impact', 9), ('insights', 8)] saved to [('august', 17), ('think', 14), ('data', 13), ('future', 11), ('infrastructure', 10), ('life', 10), ('success', 9), ('password', 9), ('impact', 9), ('insights', 8)].txt\n",
            "Article for URL_ID [('life', 19), ('august', 18), ('think', 14), ('loneliness', 13), ('impact', 13), ('robots', 11), ('infrastructure', 11), ('data', 11), ('success', 9), ('password', 9)] saved to [('life', 19), ('august', 18), ('think', 14), ('loneliness', 13), ('impact', 13), ('robots', 11), ('infrastructure', 11), ('data', 11), ('success', 9), ('password', 9)].txt\n",
            "Article for URL_ID [('august', 17), ('think', 13), ('data', 11), ('success', 10), ('infrastructure', 10), ('password', 9), ('impact', 9), ('robots', 8), ('stories', 8), ('consumer', 8)] saved to [('august', 17), ('think', 13), ('data', 11), ('success', 10), ('infrastructure', 10), ('password', 9), ('impact', 9), ('robots', 8), ('stories', 8), ('consumer', 8)].txt\n",
            "Article for URL_ID [('healthcare', 23), ('management', 20), ('august', 18), ('future', 15), ('data', 15), ('impact', 14), ('think', 13), ('patient', 11), ('services', 10), ('infrastructure', 10)] saved to [('healthcare', 23), ('management', 20), ('august', 18), ('future', 15), ('data', 15), ('impact', 14), ('think', 13), ('patient', 11), ('services', 10), ('infrastructure', 10)].txt\n",
            "Article for URL_ID [('nuclear', 20), ('august', 17), ('think', 13), ('infrastructure', 10), ('data', 10), ('impact', 10), ('insights', 9), ('success', 9), ('password', 9), ('people', 9)] saved to [('nuclear', 20), ('august', 17), ('think', 13), ('infrastructure', 10), ('data', 10), ('impact', 10), ('insights', 9), ('success', 9), ('password', 9), ('people', 9)].txt\n",
            "Article for URL_ID [('animal', 19), ('august', 17), ('testing', 15), ('animals', 15), ('think', 14), ('data', 11), ('infrastructure', 10), ('impact', 10), ('human', 10), ('success', 9)] saved to [('animal', 19), ('august', 17), ('testing', 15), ('animals', 15), ('think', 14), ('data', 11), ('infrastructure', 10), ('impact', 10), ('human', 10), ('success', 9)].txt\n",
            "Article for URL_ID [('consciousness', 34), ('brain', 22), ('august', 18), ('think', 13), ('data', 13), ('memory', 12), ('infrastructure', 10), ('life', 10), ('one', 10), ('success', 9)] saved to [('consciousness', 34), ('brain', 22), ('august', 18), ('think', 13), ('data', 13), ('memory', 12), ('infrastructure', 10), ('life', 10), ('one', 10), ('success', 9)].txt\n",
            "Article for URL_ID [('space', 29), ('august', 17), ('think', 14), ('infrastructure', 13), ('life', 11), ('like', 11), ('environment', 10), ('outer', 9), ('success', 9), ('data', 9)] saved to [('space', 29), ('august', 17), ('think', 14), ('infrastructure', 13), ('life', 11), ('like', 11), ('environment', 10), ('outer', 9), ('success', 9), ('data', 9)].txt\n",
            "Article for URL_ID [('august', 18), ('think', 14), ('year', 12), ('human', 12), ('insights', 10), ('infrastructure', 10), ('success', 9), ('password', 9), ('impact', 9), ('life', 9)] saved to [('august', 18), ('think', 14), ('year', 12), ('human', 12), ('insights', 10), ('infrastructure', 10), ('success', 9), ('password', 9), ('impact', 9), ('life', 9)].txt\n",
            "Article for URL_ID [('business', 18), ('chatbot', 18), ('august', 18), ('think', 14), ('stories', 11), ('infrastructure', 10), ('data', 10), ('sakamoto', 10), ('insights', 9), ('success', 9)] saved to [('business', 18), ('chatbot', 18), ('august', 18), ('think', 14), ('stories', 11), ('infrastructure', 10), ('data', 10), ('sakamoto', 10), ('insights', 9), ('success', 9)].txt\n",
            "Article for URL_ID [('august', 18), ('leaders', 18), ('technical', 15), ('think', 14), ('leader', 14), ('impact', 12), ('great', 12), ('infrastructure', 10), ('data', 10), ('know', 10)] saved to [('august', 18), ('leaders', 18), ('technical', 15), ('think', 14), ('leader', 14), ('impact', 12), ('great', 12), ('infrastructure', 10), ('data', 10), ('know', 10)].txt\n",
            "Article for URL_ID [('august', 18), ('think', 14), ('leader', 11), ('infrastructure', 11), ('data', 11), ('expertise', 10), ('impact', 10), ('technical', 9), ('success', 9), ('password', 9)] saved to [('august', 18), ('think', 14), ('leader', 11), ('infrastructure', 11), ('data', 11), ('expertise', 10), ('impact', 10), ('technical', 9), ('success', 9), ('password', 9)].txt\n",
            "Article for URL_ID [('ai', 40), ('data', 24), ('august', 19), ('environment', 17), ('climate', 17), ('impact', 16), ('think', 15), ('learning', 14), ('energy', 12), ('intelligence', 11)] saved to [('ai', 40), ('data', 24), ('august', 19), ('environment', 17), ('climate', 17), ('impact', 16), ('think', 15), ('learning', 14), ('energy', 12), ('intelligence', 11)].txt\n",
            "Article for URL_ID [('august', 19), ('data', 17), ('think', 16), ('fear', 12), ('making', 11), ('impact', 11), ('infrastructure', 10), ('mistakes', 9), ('success', 9), ('password', 9)] saved to [('august', 19), ('data', 17), ('think', 16), ('fear', 12), ('making', 11), ('impact', 11), ('infrastructure', 10), ('mistakes', 9), ('success', 9), ('password', 9)].txt\n",
            "Article for URL_ID [('august', 19), ('think', 15), ('stool', 14), ('perfection', 12), ('manish', 12), ('vinay', 12), ('data', 11), ('impact', 11), ('task', 11), ('sameer', 11)] saved to [('august', 19), ('think', 15), ('stool', 14), ('perfection', 12), ('manish', 12), ('vinay', 12), ('data', 11), ('impact', 11), ('task', 11), ('sameer', 11)].txt\n",
            "Article for URL_ID [('banks', 22), ('august', 20), ('loans', 19), ('credit', 17), ('cdos', 16), ('started', 15), ('investors', 15), ('crisis', 14), ('think', 14), ('impact', 11)] saved to [('banks', 22), ('august', 20), ('loans', 19), ('credit', 17), ('cdos', 16), ('started', 15), ('investors', 15), ('crisis', 14), ('think', 14), ('impact', 11)].txt\n",
            "Article for URL_ID [('gender', 34), ('diversity', 19), ('women', 19), ('august', 18), ('think', 14), ('data', 12), ('infrastructure', 10), ('impact', 10), ('men', 10), ('workplace', 10)] saved to [('gender', 34), ('diversity', 19), ('women', 19), ('august', 18), ('think', 14), ('data', 12), ('infrastructure', 10), ('impact', 10), ('men', 10), ('workplace', 10)].txt\n",
            "Article for URL_ID [('august', 19), ('think', 16), ('data', 14), ('fear', 12), ('making', 11), ('impact', 11), ('infrastructure', 10), ('mistakes', 9), ('success', 9), ('password', 9)] saved to [('august', 19), ('think', 16), ('data', 14), ('fear', 12), ('making', 11), ('impact', 11), ('infrastructure', 10), ('mistakes', 9), ('success', 9), ('password', 9)].txt\n",
            "Article for URL_ID [('business', 22), ('august', 19), ('businesses', 17), ('small', 16), ('think', 14), ('cash', 13), ('impact', 12), ('success', 10), ('infrastructure', 10), ('environment', 10)] saved to [('business', 22), ('august', 19), ('businesses', 17), ('small', 16), ('think', 14), ('cash', 13), ('impact', 12), ('success', 10), ('infrastructure', 10), ('environment', 10)].txt\n",
            "Article for URL_ID [('vendors', 26), ('august', 19), ('think', 15), ('data', 14), ('impact', 12), ('government', 11), ('infrastructure', 10), ('food', 9), ('success', 9), ('consumer', 9)] saved to [('vendors', 26), ('august', 19), ('think', 15), ('data', 14), ('impact', 12), ('government', 11), ('infrastructure', 10), ('food', 9), ('success', 9), ('consumer', 9)].txt\n",
            "Article for URL_ID [('vendors', 32), ('august', 17), ('think', 14), ('impact', 14), ('fresh', 14), ('data', 13), ('vegetable', 12), ('government', 12), ('food', 12), ('infrastructure', 11)] saved to [('vendors', 32), ('august', 17), ('think', 14), ('impact', 14), ('fresh', 14), ('data', 13), ('vegetable', 12), ('government', 12), ('food', 12), ('infrastructure', 11)].txt\n",
            "Article for URL_ID [('august', 18), ('impact', 14), ('tourism', 14), ('think', 14), ('industries', 13), ('economy', 13), ('people', 13), ('aviation', 12), ('business', 12), ('pandemic', 11)] saved to [('august', 18), ('impact', 14), ('tourism', 14), ('think', 14), ('industries', 13), ('economy', 13), ('people', 13), ('aviation', 12), ('business', 12), ('pandemic', 11)].txt\n",
            "Article for URL_ID [('world', 49), ('postponed', 49), ('may', 46), ('cancelled', 40), ('june', 37), ('league', 35), ('scheduled', 32), ('july', 30), ('season', 30), ('cup', 24)] saved to [('world', 49), ('postponed', 49), ('may', 46), ('cancelled', 40), ('june', 37), ('league', 35), ('scheduled', 32), ('july', 30), ('season', 30), ('cup', 24)].txt\n",
            "Article for URL_ID [('august', 17), ('data', 14), ('think', 13), ('services', 12), ('lockdown', 12), ('infrastructure', 11), ('economy', 11), ('online', 10), ('cities', 10), ('impact', 10)] saved to [('august', 17), ('data', 14), ('think', 13), ('services', 12), ('lockdown', 12), ('infrastructure', 11), ('economy', 11), ('online', 10), ('cities', 10), ('impact', 10)].txt\n",
            "Article for URL_ID [('gaming', 38), ('video', 38), ('games', 20), ('online', 17), ('august', 17), ('think', 14), ('disorder', 14), ('game', 13), ('playing', 13), ('impact', 11)] saved to [('gaming', 38), ('video', 38), ('games', 20), ('online', 17), ('august', 17), ('think', 14), ('disorder', 14), ('game', 13), ('playing', 13), ('impact', 11)].txt\n",
            "Article for URL_ID [('august', 24), ('think', 15), ('impact', 13), ('infrastructure', 12), ('rising', 10), ('cities', 10), ('economy', 10), ('environment', 10), ('city', 10), ('life', 10)] saved to [('august', 24), ('think', 15), ('impact', 13), ('infrastructure', 12), ('rising', 10), ('cities', 10), ('economy', 10), ('environment', 10), ('city', 10), ('life', 10)].txt\n",
            "Article for URL_ID [('voice', 33), ('august', 24), ('search', 20), ('think', 17), ('business', 14), ('impact', 13), ('infrastructure', 12), ('life', 11), ('data', 10), ('rising', 10)] saved to [('voice', 33), ('august', 24), ('search', 20), ('think', 17), ('business', 14), ('impact', 13), ('infrastructure', 12), ('life', 11), ('data', 10), ('rising', 10)].txt\n",
            "Article for URL_ID [('companies', 20), ('august', 18), ('going', 17), ('would', 17), ('think', 15), ('economy', 15), ('employees', 15), ('pandemic', 14), ('services', 13), ('infrastructure', 12)] saved to [('companies', 20), ('august', 18), ('going', 17), ('would', 17), ('think', 15), ('economy', 15), ('employees', 15), ('pandemic', 14), ('services', 13), ('infrastructure', 12)].txt\n",
            "Article for URL_ID [('brand', 27), ('social', 26), ('media', 21), ('marketing', 21), ('august', 19), ('think', 14), ('engagement', 12), ('customer', 12), ('online', 11), ('impact', 11)] saved to [('brand', 27), ('social', 26), ('media', 21), ('marketing', 21), ('august', 19), ('think', 14), ('engagement', 12), ('customer', 12), ('online', 11), ('impact', 11)].txt\n",
            "Article for URL_ID [('food', 19), ('august', 17), ('impact', 15), ('need', 14), ('think', 13), ('vendors', 12), ('infrastructure', 11), ('government', 10), ('economy', 10), ('life', 10)] saved to [('food', 19), ('august', 17), ('impact', 15), ('need', 14), ('think', 13), ('vendors', 12), ('infrastructure', 11), ('government', 10), ('economy', 10), ('life', 10)].txt\n",
            "Article for URL_ID [('impact', 22), ('energy', 22), ('market', 21), ('power', 21), ('august', 17), ('electricity', 16), ('demand', 14), ('think', 13), ('would', 12), ('consumer', 11)] saved to [('impact', 22), ('energy', 22), ('market', 21), ('power', 21), ('august', 17), ('electricity', 16), ('demand', 14), ('think', 13), ('would', 12), ('consumer', 11)].txt\n",
            "Article for URL_ID [('hospitality', 20), ('impact', 18), ('august', 17), ('think', 13), ('industry', 13), ('infrastructure', 10), ('economy', 10), ('success', 9), ('data', 9), ('password', 9)] saved to [('hospitality', 20), ('impact', 18), ('august', 17), ('think', 13), ('industry', 13), ('infrastructure', 10), ('economy', 10), ('success', 9), ('data', 9), ('password', 9)].txt\n",
            "Article for URL_ID [('august', 17), ('crisis', 13), ('think', 13), ('past', 11), ('infrastructure', 11), ('impact', 11), ('economy', 10), ('must', 10), ('success', 9), ('data', 9)] saved to [('august', 17), ('crisis', 13), ('think', 13), ('past', 11), ('infrastructure', 11), ('impact', 11), ('economy', 10), ('must', 10), ('success', 9), ('data', 9)].txt\n",
            "Article for URL_ID [('august', 17), ('impact', 15), ('think', 14), ('infrastructure', 14), ('economy', 14), ('environment', 12), ('consumer', 10), ('data', 10), ('success', 9), ('password', 9)] saved to [('august', 17), ('impact', 15), ('think', 14), ('infrastructure', 14), ('economy', 14), ('environment', 12), ('consumer', 10), ('data', 10), ('success', 9), ('password', 9)].txt\n",
            "Article for URL_ID [('august', 24), ('bri', 21), ('impact', 16), ('think', 15), ('infrastructure', 14), ('globalization', 14), ('china', 14), ('world', 13), ('economy', 11), ('city', 11)] saved to [('august', 24), ('bri', 21), ('impact', 16), ('think', 15), ('infrastructure', 14), ('globalization', 14), ('china', 14), ('world', 13), ('economy', 11), ('city', 11)].txt\n",
            "Article for URL_ID [('august', 17), ('think', 14), ('impact', 11), ('infrastructure', 10), ('data', 10), ('success', 9), ('password', 9), ('economy', 9), ('insights', 8), ('stories', 8)] saved to [('august', 17), ('think', 14), ('impact', 11), ('infrastructure', 10), ('data', 10), ('success', 9), ('password', 9), ('economy', 9), ('insights', 8), ('stories', 8)].txt\n",
            "Article for URL_ID [('gaming', 17), ('august', 17), ('think', 13), ('online', 12), ('year', 11), ('infrastructure', 10), ('data', 10), ('impact', 10), ('sam', 10), ('insights', 9)] saved to [('gaming', 17), ('august', 17), ('think', 13), ('online', 12), ('year', 11), ('infrastructure', 10), ('data', 10), ('impact', 10), ('sam', 10), ('insights', 9)].txt\n",
            "Article for URL_ID [('environment', 18), ('august', 17), ('think', 14), ('impact', 12), ('infrastructure', 10), ('success', 9), ('data', 9), ('password', 9), ('rising', 9), ('economy', 9)] saved to [('environment', 18), ('august', 17), ('think', 14), ('impact', 12), ('infrastructure', 10), ('success', 9), ('data', 9), ('password', 9), ('rising', 9), ('economy', 9)].txt\n",
            "Article for URL_ID [('august', 17), ('think', 13), ('due', 12), ('environment', 12), ('data', 12), ('supply', 11), ('impact', 11), ('economy', 11), ('infrastructure', 10), ('success', 9)] saved to [('august', 17), ('think', 13), ('due', 12), ('environment', 12), ('data', 12), ('supply', 11), ('impact', 11), ('economy', 11), ('infrastructure', 10), ('success', 9)].txt\n",
            "Article for URL_ID [('impact', 18), ('august', 17), ('employees', 15), ('space', 14), ('think', 13), ('infrastructure', 12), ('people', 12), ('might', 11), ('office', 9), ('success', 9)] saved to [('impact', 18), ('august', 17), ('employees', 15), ('space', 14), ('think', 13), ('infrastructure', 12), ('people', 12), ('might', 11), ('office', 9), ('success', 9)].txt\n",
            "Article for URL_ID [('august', 17), ('handicrafts', 14), ('think', 14), ('indian', 13), ('economy', 12), ('impact', 11), ('arts', 10), ('infrastructure', 10), ('data', 10), ('industry', 10)] saved to [('august', 17), ('handicrafts', 14), ('think', 14), ('indian', 13), ('economy', 12), ('impact', 11), ('arts', 10), ('infrastructure', 10), ('data', 10), ('industry', 10)].txt\n",
            "Article for URL_ID [('august', 24), ('online', 22), ('think', 16), ('payment', 14), ('infrastructure', 12), ('impact', 12), ('rising', 10), ('cities', 10), ('economy', 10), ('environment', 10)] saved to [('august', 24), ('online', 22), ('think', 16), ('payment', 14), ('infrastructure', 12), ('impact', 12), ('rising', 10), ('cities', 10), ('economy', 10), ('environment', 10)].txt\n",
            "Article for URL_ID [('august', 24), ('think', 16), ('impact', 13), ('infrastructure', 12), ('economy', 11), ('environment', 11), ('life', 11), ('data', 10), ('rising', 10), ('cities', 10)] saved to [('august', 24), ('think', 16), ('impact', 13), ('infrastructure', 12), ('economy', 11), ('environment', 11), ('life', 11), ('data', 10), ('rising', 10), ('cities', 10)].txt\n",
            "Extraction and saving process completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Poitiive Score count"
      ],
      "metadata": {
        "id": "aCvwlXjIGAU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Excel file into a pandas DataFrame\n",
        "excel_file_path = '/content/drive/MyDrive/Input.xlsx'\n",
        "df = pd.read_excel(excel_file_path)\n",
        "\n",
        "# Assuming you have a column named 'URL_column' in your Excel file\n",
        "URL_column = 'URL'\n",
        "\n",
        "# Check if the 'URL_column' exists in the DataFrame\n",
        "if URL_column not in df.columns:\n",
        "    print(f\"Error: The column '{URL_column}' does not exist in the Excel file.\")\n",
        "else:\n",
        "    # Filter rows where the URL is not an empty string\n",
        "    non_empty_URL_rows = df[df[URL_column] != '']\n",
        "\n",
        "    # Calculate the count of non-empty URLs\n",
        "    non_empty_URL_count = len(non_empty_URL_rows)\n",
        "\n",
        "    print(f\"The count of non-empty URLs is: {non_empty_URL_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObHveb6432m4",
        "outputId": "967ed9fe-47dd-424a-a494-e7ddae301969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The count of non-empty URLs is: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Negative Score count"
      ],
      "metadata": {
        "id": "wUfITB3rIquc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "excel_file_path = '/content/drive/MyDrive/Input.xlsx'\n",
        "\n",
        "# Use the read_excel function to load the Excel file into a DataFrame\n",
        "df = pd.read_excel(excel_file_path)\n",
        "\n",
        "# Print the column names to identify the correct column\n",
        "print(\"Column Names:\", df.columns)\n",
        "\n",
        "# Replace 'negative_column' with the actual column name containing the values you want to analyze\n",
        "negative_column_name = 'Analysis Result'\n",
        "\n",
        "# Check if the column exists in the DataFrame\n",
        "if negative_column_name in df.columns:\n",
        "    # Convert the column to numeric (ignore errors for non-numeric values)\n",
        "    df[negative_column_name] = pd.to_numeric(df[negative_column_name], errors='coerce')\n",
        "\n",
        "    # Calculate the negative score\n",
        "    negative_score = df[negative_column_name][df[negative_column_name] < 0].sum()\n",
        "    print(f\"Negative Score: {negative_score}\")\n",
        "else:\n",
        "    print(f\"Column '{negative_column_name}' not found in the DataFrame.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7x3_uOOPHPGA",
        "outputId": "eb1c0675-a622-4aac-a71d-96273d02380c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column Names: Index(['URL', 'Analysis Result'], dtype='object')\n",
            "Negative Score: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. polarity Score"
      ],
      "metadata": {
        "id": "xn1Mf-pFIguB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Load the Excel file into a pandas DataFrame\n",
        "excel_file_path = '/content/drive/MyDrive/Input.xlsx'\n",
        "df = pd.read_excel(excel_file_path)\n",
        "\n",
        "# Assuming you have a column named 'Text' in your Excel file containing the text data\n",
        "URL_column = 'URL'\n",
        "\n",
        "# Create a new column 'Polarity' to store the polarity scores\n",
        "df['Polarity'] = df[URL_column].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
        "\n",
        "# Print the DataFrame with the added 'Polarity' column\n",
        "print(df)\n",
        "\n",
        "# Calculate the overall polarity score (average of all scores)\n",
        "overall_polarity = df['Polarity'].mean()\n",
        "print(f\"The overall polarity score is: {overall_polarity}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1bVyEg_H3gE",
        "outputId": "1618e1df-06c7-45c2-bd00-5985f0c44216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  URL  \\\n",
            "0   https://insights.blackcoffer.com/rising-it-cit...   \n",
            "1   https://insights.blackcoffer.com/rising-it-cit...   \n",
            "2   https://insights.blackcoffer.com/internet-dema...   \n",
            "3   https://insights.blackcoffer.com/rise-of-cyber...   \n",
            "4   https://insights.blackcoffer.com/ott-platform-...   \n",
            "..                                                ...   \n",
            "95  https://insights.blackcoffer.com/what-is-the-r...   \n",
            "96  https://insights.blackcoffer.com/impact-of-cov...   \n",
            "97  https://insights.blackcoffer.com/contribution-...   \n",
            "98  https://insights.blackcoffer.com/how-covid-19-...   \n",
            "99  https://insights.blackcoffer.com/how-will-covi...   \n",
            "\n",
            "                                      Analysis Result  Polarity  \n",
            "0   [('cities', 31), ('impact', 21), ('market', 20...       0.0  \n",
            "1   [('cities', 35), ('august', 18), ('impact', 17...       0.0  \n",
            "2   [('internet', 25), ('august', 20), ('demand', ...       0.0  \n",
            "3   [('data', 18), ('august', 18), ('cybercrime', ...       0.0  \n",
            "4   [('ott', 25), ('platforms', 19), ('august', 18...       0.0  \n",
            "..                                                ...       ...  \n",
            "95  [('august', 17), ('think', 13), ('due', 12), (...       0.0  \n",
            "96  [('impact', 18), ('august', 17), ('employees',...       0.0  \n",
            "97  [('august', 17), ('handicrafts', 14), ('think'...       0.0  \n",
            "98  [('august', 24), ('online', 22), ('think', 16)...       0.0  \n",
            "99  [('august', 24), ('think', 16), ('impact', 13)...       0.0  \n",
            "\n",
            "[100 rows x 3 columns]\n",
            "The overall polarity score is: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Subjectivity Score"
      ],
      "metadata": {
        "id": "hM3OnpH8JR_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Load the Excel file into a pandas DataFrame\n",
        "excel_file_path = '/content/drive/MyDrive/Input.xlsx'\n",
        "df = pd.read_excel(excel_file_path)\n",
        "\n",
        "# Assuming you have a column named 'Text' in your Excel file containing text data\n",
        "URL_column = 'URL'\n",
        "\n",
        "# Calculate the subjectivity score for each text entry\n",
        "df['Subjectivity'] = df[URL_column].apply(lambda x: TextBlob(str(x)).sentiment.subjectivity)\n",
        "\n",
        "# Calculate the average subjectivity score\n",
        "average_subjectivity = df['Subjectivity'].mean()\n",
        "\n",
        "print(f\"The average subjectivity score is: {average_subjectivity:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7j35VkAIx-I",
        "outputId": "8fb05679-b44e-453d-bb20-056e8225f7bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The average subjectivity score is: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Average Sentence Length"
      ],
      "metadata": {
        "id": "6G7cYxBKJt17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "excel_file_path = '/content/drive/MyDrive/Input.xlsx'\n",
        "\n",
        "# Use the read_excel function to load the Excel file into a DataFrame\n",
        "df = pd.read_excel(excel_file_path)\n"
      ],
      "metadata": {
        "id": "ql0mxnjuJY_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_column_name = 'Analysis Result'\n"
      ],
      "metadata": {
        "id": "6DlvqjYRKBf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Tokenize each row in the specified column and calculate the average sentence length\n",
        "def average_sentence_length(text):\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    return sum(len(nltk.word_tokenize(sentence)) for sentence in sentences) / len(sentences) if len(sentences) > 0 else 0\n",
        "\n",
        "# Apply the function to the specified column\n",
        "df['avg_sentence_length'] = df[text_column_name].apply(average_sentence_length)\n",
        "\n",
        "# Calculate the overall average sentence length\n",
        "overall_avg_sentence_length = df['avg_sentence_length'].mean()\n",
        "\n",
        "print(f\"Overall Average Sentence Length: {overall_avg_sentence_length}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9wG3mYdKCNP",
        "outputId": "0cf60b6a-0ee8-4d40-f3a8-f6161e5a3ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Average Sentence Length: 71.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Percentage of Complex Words"
      ],
      "metadata": {
        "id": "pU_cK3qPKTiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Download the punkt tokenizer if not already downloaded\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Function to check if a word is complex (you can modify this based on your criteria)\n",
        "def is_complex(word):\n",
        "    # For simplicity, let's consider words with more than 3 characters as complex\n",
        "    return len(word) > 3\n",
        "\n",
        "# Function to calculate the percentage of complex words in a text\n",
        "def percentage_of_complex_words(text):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    complex_words = [word for word in words if is_complex(word)]\n",
        "    return (len(complex_words) / len(words)) * 100 if len(words) > 0 else 0\n",
        "\n",
        "# Apply the function to the specified column\n",
        "df['complex_word_percentage'] = df[text_column_name].apply(percentage_of_complex_words)\n",
        "\n",
        "# Calculate the overall average percentage of complex words\n",
        "overall_complex_word_percentage = df['complex_word_percentage'].mean()\n",
        "\n",
        "print(f\"Overall Percentage of Complex Words: {overall_complex_word_percentage}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1XCMd72KF5f",
        "outputId": "33af714a-55c3-4ac0-d000-d39bcf177235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Percentage of Complex Words: 13.873239436619723%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Fog Index"
      ],
      "metadata": {
        "id": "oWA9DF_SKhIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1_10tQ1Kbbb",
        "outputId": "7a471962-660f-44df-b08c-e37d3289313e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "\n",
        "excel_file_path = '/content/drive/MyDrive/Input.xlsx'\n",
        "\n",
        "# Use the read_excel function to load the Excel file into a DataFrame\n",
        "df = pd.read_excel(excel_file_path)\n",
        "\n",
        "# Print the column names to identify the correct column\n",
        "print(\"Column Names:\", df.columns)\n",
        "\n",
        "# Replace 'text_column' with the actual column name containing the text data\n",
        "text_column_name = 'URL'\n",
        "\n",
        "# Check if the column exists in the DataFrame\n",
        "if text_column_name in df.columns:\n",
        "    # Download the punkt tokenizer if not already downloaded\n",
        "    nltk.download('punkt')\n",
        "\n",
        "    # Tokenize the text into sentences\n",
        "    df['sentences'] = df[text_column_name].apply(nltk.sent_tokenize)\n",
        "\n",
        "    # Function to calculate the FOG Index for a given text\n",
        "    def calculate_fog_index(sentences):\n",
        "        words = [word for sentence in sentences for word in nltk.word_tokenize(sentence)]\n",
        "        complex_words = [word for word in words if len(word) > 3]  # You can adjust the complexity criterion\n",
        "        fog_index = 0.4 * ((len(words) / len(sentences)) + 100 * (len(complex_words) / len(words)))\n",
        "        return fog_index\n",
        "\n",
        "    # Apply the function to the sentences column\n",
        "    df['fog_index'] = df['sentences'].apply(calculate_fog_index)\n",
        "\n",
        "    # Calculate the overall average FOG Index\n",
        "    overall_fog_index = df['fog_index'].mean()\n",
        "\n",
        "    print(f\"Overall FOG Index: {overall_fog_index}\")\n",
        "else:\n",
        "    print(f\"Column '{text_column_name}' not found in the DataFrame.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjfDe9sQKnb_",
        "outputId": "638e7d58-dd0a-4823-a1a7-0167b6b416eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column Names: Index(['URL', 'Analysis Result'], dtype='object')\n",
            "Overall FOG Index: 27.866666666666674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Average Number of Words Per Sentence"
      ],
      "metadata": {
        "id": "VHawmqKBK2x9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Input.xlsx'\n",
        "with open(file_path, 'r', encoding='latin-1') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Tokenize the text into sentences\n",
        "sentences = nltk.sent_tokenize(text)\n",
        "\n",
        "# Tokenize each sentence into words and calculate the average number of words per sentence\n",
        "words_per_sentence = [len(nltk.word_tokenize(sentence)) for sentence in sentences]\n",
        "\n",
        "average_words_per_sentence = sum(words_per_sentence) / len(words_per_sentence) if len(words_per_sentence) > 0 else 0\n",
        "\n",
        "print(f\"Average Number of Words per Sentence: {average_words_per_sentence}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6T6StSMYKuUv",
        "outputId": "cb3d2f98-491b-4124-ff18-ffbc47f56554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Number of Words per Sentence: 180.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Complex Word Count"
      ],
      "metadata": {
        "id": "DA2P4LJlLKw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def is_complex(word):\n",
        "\n",
        "    return len(word) > 3\n",
        "\n",
        "# Function to calculate the complex word count in a text\n",
        "def complex_word_count(text):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    complex_words = [word for word in words if is_complex(word)]\n",
        "    return len(complex_words)\n",
        "\n",
        "# Apply the function to the specified column\n",
        "df['complex_word_count'] = df[text_column_name].apply(complex_word_count)\n",
        "\n",
        "# Calculate the overall sum of complex word counts\n",
        "overall_complex_word_count = df['complex_word_count'].sum()\n",
        "\n",
        "print(f\"Overall Complex Word Count: {overall_complex_word_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiqghJHEK_5_",
        "outputId": "2c89e24d-48c6-47dc-8c41-01f86b8784df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Complex Word Count: 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Word Count"
      ],
      "metadata": {
        "id": "vgtSXa1kLYiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Function to calculate the word count in a text\n",
        "def word_count(text):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    return len(words)\n",
        "\n",
        "# Apply the function to the specified column\n",
        "df['word_count'] = df[text_column_name].apply(word_count)\n",
        "\n",
        "# Calculate the overall sum of word counts\n",
        "overall_word_count = df['word_count'].sum()\n",
        "\n",
        "print(f\"Overall Word Count: {overall_word_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2848fbsZLSWX",
        "outputId": "2cc0f7d3-fb1d-437f-f4c0-61b878a348e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Word Count: 300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. Syllable per Word"
      ],
      "metadata": {
        "id": "h_VYLqRoLkSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Download the cmudict resource for syllable counting\n",
        "nltk.download('cmudict')\n",
        "\n",
        "# Function to count syllables in a word\n",
        "def count_syllables(word):\n",
        "    # Use the CMU Pronouncing Dictionary for syllable counting\n",
        "    arpabet = nltk.corpus.cmudict.dict()\n",
        "    return max([len(list(y for y in x if y[-1].isdigit())) for x in arpabet[word.lower()]]) if word.lower() in arpabet else 0\n",
        "\n",
        "# Function to calculate the average number of syllables per word in a text\n",
        "def syllables_per_word(text):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    syllable_count = sum(count_syllables(word) for word in words)\n",
        "    return syllable_count / len(words) if len(words) > 0 else 0\n",
        "\n",
        "# Apply the function to the specified column\n",
        "df['syllables_per_word'] = df[text_column_name].apply(syllables_per_word)\n",
        "\n",
        "# Calculate the overall average number of syllables per word\n",
        "overall_syllables_per_word = df['syllables_per_word'].mean()\n",
        "\n",
        "print(f\"Overall Average Syllables per Word: {overall_syllables_per_word}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SagRqkyxLqW_",
        "outputId": "90e5714a-9c88-4dcb-9c4f-8c815a94f448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Package cmudict is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Average Syllables per Word: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. Personal Pronouns"
      ],
      "metadata": {
        "id": "uFeDWXQ5L40l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Function to count personal pronouns in a text\n",
        "def count_personal_pronouns(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tagged_words = pos_tag(tokens)\n",
        "\n",
        "    # List of personal pronouns (can extend this list if needed)\n",
        "    personal_pronouns = ['I', 'me', 'my', 'mine', 'myself', 'you', 'your', 'yours', 'yourself',\n",
        "                         'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself',\n",
        "                         'it', 'its', 'itself', 'we', 'us', 'our', 'ours', 'ourselves',\n",
        "                         'they', 'them', 'their', 'theirs', 'themselves']\n",
        "\n",
        "    # Count personal pronouns\n",
        "    pronoun_count = sum(1 for word, pos in tagged_words if pos == 'PRP' and word.lower() in personal_pronouns)\n",
        "\n",
        "    return pronoun_count\n",
        "\n",
        "# Apply the function to the specified column\n",
        "df['personal_pronoun_count'] = df[text_column_name].apply(count_personal_pronouns)\n",
        "\n",
        "# Calculate the overall count of personal pronouns\n",
        "overall_personal_pronoun_count = df['personal_pronoun_count'].sum()\n",
        "\n",
        "print(f\"Overall Count of Personal Pronouns: {overall_personal_pronoun_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcPXdWNbLrIf",
        "outputId": "29a5daa3-6da8-4d6a-9298-fb845d83574d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Count of Personal Pronouns: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14. Average Word Length"
      ],
      "metadata": {
        "id": "7IZakGFUMdVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the average word length in a text\n",
        "def average_word_length(text):\n",
        "    words = text.split()\n",
        "    word_lengths = [len(word) for word in words]\n",
        "    return sum(word_lengths) / len(word_lengths) if len(word_lengths) > 0 else 0\n",
        "\n",
        "# Apply the function to the specified column\n",
        "df['average_word_length'] = df[text_column_name].apply(average_word_length)\n",
        "\n",
        "# Calculate the overall average word length\n",
        "overall_average_word_length = df['average_word_length'].mean()\n",
        "\n",
        "print(f\"Overall Average Word Length: {overall_average_word_length}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VYAkMblMEBB",
        "outputId": "6e20f4e6-2a47-4608-9592-2e7f8177fdcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Average Word Length: 92.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.We can directly click the link and can run it in google colab\n"
      ],
      "metadata": {
        "id": "nz7247XVSpNI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dEJQTQsxZ7NG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}